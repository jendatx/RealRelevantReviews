{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model: Logistic Regression\n",
    "\n",
    "**THIS IS NOW AN EXPLORATION NOTEBOOK**\n",
    "\n",
    "**_Actual_** baseline logistic regression model with large training set is located in `baseline_logreg_cluster`\n",
    "\n",
    "This notebook was used to spot-check various data subsetting and sampling techniques, as well as experiment with TF-IDF vectorizer parameters, truncated SVD, and logistic regression tuning.\n",
    "\n",
    "**BEGIN ORIGINAL FILE**\n",
    "\n",
    "**Initial Approach:**\n",
    "1. Recreate data preparation procedure from \"Predicting Amazon Book Review Helpfulness using BERT on TF Hub\"\n",
    "2. Train/evaluate a logistic regression model with no parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Brad\\\\Desktop\\\\Keras - GPU\\\\Baseline Models'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset by sampling labeled_dev_set.csv\n",
    "# - 314,080 reviews\n",
    "my_data = \"Data/labeled/labeled_dev_set.csv\"\n",
    "mine = pd.read_csv(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314080, 15)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>review_age_days</th>\n",
       "      <th>annual_HVAR</th>\n",
       "      <th>book_num_reviews</th>\n",
       "      <th>std_HVAR</th>\n",
       "      <th>top_quartile_HVAR</th>\n",
       "      <th>most_helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>5</td>\n",
       "      <td>I would have to say that this is the best book...</td>\n",
       "      <td>2001-02-24</td>\n",
       "      <td>A26GKZPS079GFF</td>\n",
       "      <td>Areej</td>\n",
       "      <td>Touches my heart.. again and.. again...</td>\n",
       "      <td>982972800</td>\n",
       "      <td>2</td>\n",
       "      <td>4897</td>\n",
       "      <td>0.149071</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.930287</td>\n",
       "      <td>0.842702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>5</td>\n",
       "      <td>This is Gibran's most celebrated work and it i...</td>\n",
       "      <td>2000-05-03</td>\n",
       "      <td>A15ACUAJEJXCS3</td>\n",
       "      <td>Caz</td>\n",
       "      <td>Superb</td>\n",
       "      <td>957312000</td>\n",
       "      <td>1</td>\n",
       "      <td>5194</td>\n",
       "      <td>0.070273</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.930287</td>\n",
       "      <td>0.842702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>5</td>\n",
       "      <td>Gibran Khalil Gibran was born in 1883 in what ...</td>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>AWLFVCT9128JV</td>\n",
       "      <td>Dave_42 \"Dave_42\"</td>\n",
       "      <td>The Lessons Of Life</td>\n",
       "      <td>1136851200</td>\n",
       "      <td>8</td>\n",
       "      <td>3116</td>\n",
       "      <td>0.937099</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.930287</td>\n",
       "      <td>0.842702</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>5</td>\n",
       "      <td>_The Prophet_ is a short read (my copy checks ...</td>\n",
       "      <td>2012-08-12</td>\n",
       "      <td>A2NHD7LUXVGTD3</td>\n",
       "      <td>doc peterson</td>\n",
       "      <td>a beautiful poetic commentary on what it is to...</td>\n",
       "      <td>1344729600</td>\n",
       "      <td>1</td>\n",
       "      <td>710</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.930287</td>\n",
       "      <td>0.842702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>5</td>\n",
       "      <td>The Prophet, for me, is a very vivid yet dense...</td>\n",
       "      <td>2007-11-29</td>\n",
       "      <td>AAEP8YFERQ8FC</td>\n",
       "      <td>General Breadbasket</td>\n",
       "      <td>Speak to Us of the Prophet</td>\n",
       "      <td>1196294400</td>\n",
       "      <td>1</td>\n",
       "      <td>2428</td>\n",
       "      <td>0.150329</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.930287</td>\n",
       "      <td>0.842702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  000100039X        5  I would have to say that this is the best book...   \n",
       "1  000100039X        5  This is Gibran's most celebrated work and it i...   \n",
       "2  000100039X        5  Gibran Khalil Gibran was born in 1883 in what ...   \n",
       "3  000100039X        5  _The Prophet_ is a short read (my copy checks ...   \n",
       "4  000100039X        5  The Prophet, for me, is a very vivid yet dense...   \n",
       "\n",
       "   reviewTime      reviewerID         reviewerName  \\\n",
       "0  2001-02-24  A26GKZPS079GFF                Areej   \n",
       "1  2000-05-03  A15ACUAJEJXCS3                  Caz   \n",
       "2  2006-01-10   AWLFVCT9128JV    Dave_42 \"Dave_42\"   \n",
       "3  2012-08-12  A2NHD7LUXVGTD3         doc peterson   \n",
       "4  2007-11-29   AAEP8YFERQ8FC  General Breadbasket   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0            Touches my heart.. again and.. again...       982972800   \n",
       "1                                             Superb       957312000   \n",
       "2                                The Lessons Of Life      1136851200   \n",
       "3  a beautiful poetic commentary on what it is to...      1344729600   \n",
       "4                         Speak to Us of the Prophet      1196294400   \n",
       "\n",
       "   helpful_votes  review_age_days  annual_HVAR  book_num_reviews  std_HVAR  \\\n",
       "0              2             4897     0.149071              86.0  2.930287   \n",
       "1              1             5194     0.070273              86.0  2.930287   \n",
       "2              8             3116     0.937099              86.0  2.930287   \n",
       "3              1              710     0.514085              86.0  2.930287   \n",
       "4              1             2428     0.150329              86.0  2.930287   \n",
       "\n",
       "   top_quartile_HVAR  most_helpful  \n",
       "0           0.842702             0  \n",
       "1           0.842702             0  \n",
       "2           0.842702             1  \n",
       "3           0.842702             0  \n",
       "4           0.842702             0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup reviews without review content\n",
    "#mine.iloc[94073]['reviewText'] # Example has 'nan' as reviewText\n",
    "mine.dropna(subset=['reviewText'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32445"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many reviews have exactly 0 helpful votes?\n",
    "sum(mine.helpful_votes == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_helpful: (10061, 15)\n",
      "neg_unhelpful: (1504, 15)\n",
      "pos_unhelpful: (14786, 15)\n",
      "pos_helpful: (40648, 15)\n"
     ]
    }
   ],
   "source": [
    "# How many examples of each group?\n",
    "print('neg_helpful: {}'.format(mine[(mine.overall == 1) & (mine.most_helpful == 1) & (mine.helpful_votes != 0)].shape))\n",
    "print('neg_unhelpful: {}'.format(mine[(mine.overall == 1) & (mine.most_helpful == 0) & (mine.helpful_votes == 0)].shape))\n",
    "print('pos_unhelpful: {}'.format(mine[(mine.overall == 5) & (mine.most_helpful == 0) & (mine.helpful_votes == 0)].shape))\n",
    "print('pos_helpful: {}'.format(mine[(mine.overall == 5) & (mine.most_helpful == 1) & (mine.helpful_votes != 0)].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below I sample to have equal amounts of pos/neg reviews and equal amounts of top-quartile-HVAR vs 0 helpful votes\n",
    "num_per_condition = 2000\n",
    "repl=True\n",
    "neg_helpful = mine[(mine.overall == 1) & (mine.most_helpful == 1) & (mine.helpful_votes != 0)].sample(num_per_condition, replace=repl)\n",
    "neg_unhelpful = mine[(mine.overall == 1) & (mine.most_helpful == 0) & (mine.helpful_votes == 0)].sample(num_per_condition, replace=repl)\n",
    "pos_unhelpful = mine[(mine.overall == 5) & (mine.most_helpful == 0) & (mine.helpful_votes == 0)].sample(num_per_condition, replace=repl)\n",
    "pos_helpful = mine[(mine.overall == 5) & (mine.most_helpful == 1) & (mine.helpful_votes != 0)].sample(num_per_condition, replace=repl)\n",
    "# \"reviewText\" has the review content\n",
    "# \"most_helpful\" has the label of 0 or 1\n",
    "# \"overall\" has the star-rating {1,2,3,4,5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with prepending TEXT representation of starts to the reviews, \n",
    "# as a way to pass overall rating to our classifier\n",
    "# because haven't figured out how to send categorical data AROUND the transformer yet\n",
    "neg_helpful['prepReviewText'] = neg_helpful.apply(lambda x: 'WORST ' + x.reviewText,axis = 1)\n",
    "neg_unhelpful['prepReviewText'] = neg_unhelpful.apply(lambda x: 'WORST ' + x.reviewText,axis = 1)\n",
    "pos_unhelpful['prepReviewText'] = pos_unhelpful.apply(lambda x: 'BEST ' + x.reviewText,axis = 1)\n",
    "pos_helpful['prepReviewText'] = pos_helpful.apply(lambda x: 'BEST ' + x.reviewText,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311546    WORST The beginning of this terrible tale is r...\n",
       "304382    WORST Poorly organized and written by someone ...\n",
       "303849    WORST I'm just not sure where to start. The st...\n",
       "298457    WORST I agree with the majority of the reviewe...\n",
       "306659    WORST Isn't Steampunk just a rip-off of that h...\n",
       "Name: prepReviewText, dtype: object"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_helpful['prepReviewText'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>review_age_days</th>\n",
       "      <th>annual_HVAR</th>\n",
       "      <th>book_num_reviews</th>\n",
       "      <th>std_HVAR</th>\n",
       "      <th>top_quartile_HVAR</th>\n",
       "      <th>most_helpful</th>\n",
       "      <th>prepReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312111</th>\n",
       "      <td>1621050203</td>\n",
       "      <td>1</td>\n",
       "      <td>I hate this book. I don't say that lightly or ...</td>\n",
       "      <td>2013-07-15</td>\n",
       "      <td>A2NZNCKZYZYJ5G</td>\n",
       "      <td>Zep Greenfelder</td>\n",
       "      <td>spoiler alert</td>\n",
       "      <td>1373846400</td>\n",
       "      <td>3</td>\n",
       "      <td>373</td>\n",
       "      <td>2.935657</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.978833</td>\n",
       "      <td>2.703704</td>\n",
       "      <td>1</td>\n",
       "      <td>WORST I hate this book. I don't say that light...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298198</th>\n",
       "      <td>0312342020</td>\n",
       "      <td>1</td>\n",
       "      <td>This was one of the most annoying books I've e...</td>\n",
       "      <td>2010-04-25</td>\n",
       "      <td>A13Z3RD1MKC0HB</td>\n",
       "      <td>S. B.</td>\n",
       "      <td>Very Annoying Read!</td>\n",
       "      <td>1272153600</td>\n",
       "      <td>7</td>\n",
       "      <td>1550</td>\n",
       "      <td>1.648387</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3.227744</td>\n",
       "      <td>0.962214</td>\n",
       "      <td>1</td>\n",
       "      <td>WORST This was one of the most annoying books ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303084</th>\n",
       "      <td>0465019358</td>\n",
       "      <td>1</td>\n",
       "      <td>Like the previous reviewer, I am very impresse...</td>\n",
       "      <td>2011-04-08</td>\n",
       "      <td>A1XIDKCJ7SOVXP</td>\n",
       "      <td>Jackal</td>\n",
       "      <td>Big disappointment given the credentials of th...</td>\n",
       "      <td>1302220800</td>\n",
       "      <td>10</td>\n",
       "      <td>1202</td>\n",
       "      <td>3.036606</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.052057</td>\n",
       "      <td>1.868880</td>\n",
       "      <td>1</td>\n",
       "      <td>WORST Like the previous reviewer, I am very im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300184</th>\n",
       "      <td>0373712553</td>\n",
       "      <td>1</td>\n",
       "      <td>I was very excited to see that Harlequin was c...</td>\n",
       "      <td>2005-02-14</td>\n",
       "      <td>ANC8FA4FHFMCY</td>\n",
       "      <td>Winnie G</td>\n",
       "      <td>Did not live up to the Harlequin hype!</td>\n",
       "      <td>1108339200</td>\n",
       "      <td>21</td>\n",
       "      <td>3446</td>\n",
       "      <td>2.224318</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.819350</td>\n",
       "      <td>1.164781</td>\n",
       "      <td>1</td>\n",
       "      <td>WORST I was very excited to see that Harlequin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301986</th>\n",
       "      <td>0425269205</td>\n",
       "      <td>1</td>\n",
       "      <td>I too used to read the Sookie books in one sit...</td>\n",
       "      <td>2013-05-20</td>\n",
       "      <td>A3Q9QTWU49BSL9</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Such a disappointment</td>\n",
       "      <td>1369008000</td>\n",
       "      <td>35</td>\n",
       "      <td>429</td>\n",
       "      <td>29.778555</td>\n",
       "      <td>964.0</td>\n",
       "      <td>32.592742</td>\n",
       "      <td>23.153407</td>\n",
       "      <td>1</td>\n",
       "      <td>WORST I too used to read the Sookie books in o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin  overall  \\\n",
       "312111  1621050203        1   \n",
       "298198  0312342020        1   \n",
       "303084  0465019358        1   \n",
       "300184  0373712553        1   \n",
       "301986  0425269205        1   \n",
       "\n",
       "                                               reviewText  reviewTime  \\\n",
       "312111  I hate this book. I don't say that lightly or ...  2013-07-15   \n",
       "298198  This was one of the most annoying books I've e...  2010-04-25   \n",
       "303084  Like the previous reviewer, I am very impresse...  2011-04-08   \n",
       "300184  I was very excited to see that Harlequin was c...  2005-02-14   \n",
       "301986  I too used to read the Sookie books in one sit...  2013-05-20   \n",
       "\n",
       "            reviewerID     reviewerName  \\\n",
       "312111  A2NZNCKZYZYJ5G  Zep Greenfelder   \n",
       "298198  A13Z3RD1MKC0HB            S. B.   \n",
       "303084  A1XIDKCJ7SOVXP           Jackal   \n",
       "300184   ANC8FA4FHFMCY         Winnie G   \n",
       "301986  A3Q9QTWU49BSL9  Amazon Customer   \n",
       "\n",
       "                                                  summary  unixReviewTime  \\\n",
       "312111                                      spoiler alert      1373846400   \n",
       "298198                                Very Annoying Read!      1272153600   \n",
       "303084  Big disappointment given the credentials of th...      1302220800   \n",
       "300184             Did not live up to the Harlequin hype!      1108339200   \n",
       "301986                              Such a disappointment      1369008000   \n",
       "\n",
       "        helpful_votes  review_age_days  annual_HVAR  book_num_reviews  \\\n",
       "312111              3              373     2.935657               9.0   \n",
       "298198              7             1550     1.648387              85.0   \n",
       "303084             10             1202     3.036606              10.0   \n",
       "300184             21             3446     2.224318               5.0   \n",
       "301986             35              429    29.778555             964.0   \n",
       "\n",
       "         std_HVAR  top_quartile_HVAR  most_helpful  \\\n",
       "312111   1.978833           2.703704             1   \n",
       "298198   3.227744           0.962214             1   \n",
       "303084   4.052057           1.868880             1   \n",
       "300184   0.819350           1.164781             1   \n",
       "301986  32.592742          23.153407             1   \n",
       "\n",
       "                                           prepReviewText  \n",
       "312111  WORST I hate this book. I don't say that light...  \n",
       "298198  WORST This was one of the most annoying books ...  \n",
       "303084  WORST Like the previous reviewer, I am very im...  \n",
       "300184  WORST I was very excited to see that Harlequin...  \n",
       "301986  WORST I too used to read the Sookie books in o...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_helpful.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset is now 8000 reviews.\n"
     ]
    }
   ],
   "source": [
    "# Put the subsets into the same dataframe again\n",
    "stratdf = neg_helpful.append(neg_unhelpful, ignore_index=True)\n",
    "stratdf = stratdf.append(pos_unhelpful, ignore_index=True)\n",
    "stratdf = stratdf.append(pos_helpful, ignore_index=True)\n",
    "print(f\"Our dataset is now {stratdf.shape[0]} reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(stratdf,random_state=42)[['reviewText','overall','most_helpful']]\n",
    "df_prep = shuffle(stratdf,random_state=42)[['prepReviewText','overall','most_helpful']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Text\n",
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(df.reviewText,df.most_helpful, test_size=0.2, \\\n",
    "                                    random_state=42,stratify=df.most_helpful)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepended Text\n",
    "X_train_prep, X_test_prep, y_train_prep, y_test_prep = train_test_split(df_prep.prepReviewText,df_prep.most_helpful, test_size=0.2, \\\n",
    "                                   random_state=42,stratify=df_prep.most_helpful)\n",
    "# Ideally I would like to stratify such that train and test have stratified samples across\n",
    "# BOTH the most_helpful values AND the overall rating, but I keep getting errors when I try to do that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build stemming tokenizer\n",
    "# - stemming seems to limit the model too much\n",
    "\n",
    "import nltk\n",
    "def Tokenizer(str_input):\n",
    "    words = re.sub(r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'|\\*|\\-|\\;|\\:|\\,|\\.\", \" \", str_input).lower().split()\n",
    "    porter_stemmer=nltk.PorterStemmer()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count: 100000\n"
     ]
    }
   ],
   "source": [
    "# Transform text examples\n",
    "\n",
    "# sklearn tfidfvectorizer default token_pattern is a regexp that removes punctuation\n",
    "# - Leave out token_pattern to have default response (token_pattern=’(?u)\\b\\w\\w+\\b’)\n",
    "# - add-in your own regex to retain punctuation\n",
    "\n",
    "\n",
    "# consider additional parameter options:\n",
    "#    token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'|\\*|\\-|\\;|\\:|\\,|\\.\"\n",
    "#    min_df=100\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                             #tokenizer=Tokenizer,\n",
    "                             analyzer='word',\n",
    "                             stop_words=None,\n",
    "                             token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'|\\*|\\-|\\;|\\:|\\,|\\.\",\n",
    "                             ngram_range=(1,3),\n",
    "                             max_features=100000)\n",
    "\n",
    "X_train_prep_vec = vectorizer.fit_transform(X_train_prep)\n",
    "X_test_prep_vec = vectorizer.transform(X_test_prep)\n",
    "\n",
    "print(\"Token Count: {}\".format(len(vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 67 epochs took 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=42, solver='saga', tol=0.0001,\n",
       "          verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more than 2 classes...multinomial\n",
    "\n",
    "# binary problem\n",
    "\n",
    "# The SAGA solver is a variant of SAG that also supports the non-smooth penalty=l1 option (i.e. L1 Regularization).\n",
    "# This is therefore the solver of choice for sparse multinomial logistic regression and it’s also suitable very Large datasets.\n",
    "\n",
    "# saga handles l1 or l2 penalty\n",
    "\n",
    "# C = inverse of regularization strength; pos float; smaller = stronger regularization\n",
    "\n",
    "clf = LogisticRegression(penalty='l2',\n",
    "                         C=1.0,\n",
    "                         random_state=42,\n",
    "                         solver='saga',\n",
    "                         multi_class='ovr',\n",
    "                         max_iter=100,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_train_prep_vec, y_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted_labels = clf.predict(X_test_prep_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifer\n",
      "-------------\n",
      "\n",
      "Accuracy on test set: 0.783\n",
      "f_1 score (Weighted): 0.783\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with various f1 metrics\n",
    "f1_weighted = metrics.f1_score(y_test_prep, test_predicted_labels, average='weighted')\n",
    "accuracy = metrics.accuracy_score(y_test_prep, test_predicted_labels)\n",
    "    \n",
    "print('Logistic Regression Classifer')\n",
    "print('-------------\\n')\n",
    "print('Accuracy on test set: {:0.3f}'.format(accuracy))\n",
    "print('f_1 score (Weighted): {:0.3f}'.format(f1_weighted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    7.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 20 epochs took 0 seconds\n",
      "Best value for C: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "clf_2 = LogisticRegression(penalty='l2',\n",
    "                           C=1.0,\n",
    "                           random_state=42,\n",
    "                           solver='saga',\n",
    "                           multi_class='ovr',\n",
    "                           max_iter=100,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True)\n",
    "\n",
    "param_grid = {'C':list(np.linspace(0.1,1.0,10))}            \n",
    "clf_2 = GridSearchCV(clf_2, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=True)\n",
    "clf_2.fit(X_train_prep_vec, y_train_prep)\n",
    "best_c = round(clf_2.best_params_['C'],2)\n",
    "print('Best value for C: {}'.format(best_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 20 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit a model with the best C value\n",
    "clf_2 = LogisticRegression(penalty='l2',\n",
    "                           C=best_c,\n",
    "                           random_state=42,\n",
    "                           solver='saga',\n",
    "                           multi_class='ovr',\n",
    "                           max_iter=100,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True)\n",
    "\n",
    "clf_2.fit(X_train_prep_vec, y_train_prep)\n",
    "test_predicted_labels_2 = clf_2.predict(X_test_prep_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifer\n",
      "-------------\n",
      "\n",
      "Accuracy on test set: 0.718\n",
      "f_1 score (Weighted): 0.717\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with various f1 metrics\n",
    "f1_weighted = metrics.f1_score(y_test_prep, test_predicted_labels_2, average='weighted')\n",
    "accuracy = metrics.accuracy_score(y_test_prep, test_predicted_labels_2)\n",
    "    \n",
    "print('Logistic Regression Classifer')\n",
    "print('-------------\\n')\n",
    "print('Accuracy on test set: {:0.3f}'.format(accuracy))\n",
    "print('f_1 score (Weighted): {:0.3f}'.format(f1_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 3364\n",
      "True Positive: 3096\n",
      "False Negative: 904\n",
      "False Positive: 636\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_test_prep, test_predicted_labels_2)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_prep, test_predicted_labels_2).ravel()\n",
    "print(\"True Negative: {}\".format(tn))\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "print(\"False Negative: {}\".format(fn))\n",
    "print(\"False Positive: {}\".format(fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweaking lessons\n",
    "\n",
    "# acc improves with more data\n",
    "# use tfidf max_features and/or regularization parameter to control for overfitting\n",
    "\n",
    "# as per-group samples increase NOT using SVD is better\n",
    "# - might as well experiment with max_features\n",
    "# - 10000 features -> acc decr from 79.8 to 75.4\n",
    "# - 20000 features -> acc 76.6\n",
    "# - 100000 features -> acc 78.2\n",
    "# - 300000 features -> acc 79.4\n",
    "# - 600000 features -> acc 79.9\n",
    "# - 1000000 features -> acc 80.1\n",
    "# - 1.97mil features -> acc 79.8\n",
    "\n",
    "# 32000 examples; 100000 features -> 81.8\n",
    "#               1mil features -> 84.0\n",
    "\n",
    "# do not have vectorizer ignore any tokens (min_df, max_df)\n",
    "# do not remove stop words\n",
    "# increase to (1,3) ngrams\n",
    "# try ngrams (1,3) + truncated svd;\n",
    "# - svd 100 dim acc: .694 (c=0.95)\n",
    "# - svd 120 dim acc: .682 (C=0.95)\n",
    "# - svd 130 dim acc: .685 (C=0.86)\n",
    "# - svd 150 dim acc: .689 (C=0.91)\n",
    "# - svd 50 dim acc: .688 (C=0.91)\n",
    "# - svd 300 dim acc: .689 (C=0.67); more dimensions -> regularization works harder\n",
    "\n",
    "# More data\n",
    "# Did not oversample:\n",
    "#  - sample 1500 per group without replacement\n",
    "#  - svd 300 dim; C=1.0; acc=.732\n",
    "#  - svd 100 dim; C=1.0; acc=.725\n",
    "#  - svd 150 dim; C=0.76; acc=.732\n",
    "\n",
    "# results:\n",
    "\n",
    "#True Negative: 386\n",
    "#True Positive: 492\n",
    "#False Negative: 108\n",
    "#False Positive: 214\n",
    "\n",
    "# Oversample:\n",
    "#  - sample 2000 per group with replacement\n",
    "#  - svd 100 dim; C=0.95; acc=.742\n",
    "#  - svd 150 dim; C=0.81; acc=.745\n",
    "#  - svd 300 dim; C=1.0; acc=.751\n",
    "\n",
    "\n",
    "# oversampling underrepresented increases accuracy\n",
    "\n",
    "# Oversample (8000 total) with no SVD acc: 78.2\n",
    "\n",
    "\n",
    "\n",
    "# reduce dimensions\n",
    "# - stemming\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensions with truncated SVD\n",
    "dimensions=100\n",
    "svd = TruncatedSVD(n_components=dimensions, n_iter=5, random_state=42)\n",
    "X_train_svd = svd.fit_transform(X_train_prep_vec)\n",
    "X_test_svd = svd.transform(X_test_prep_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 17 epochs took 0 seconds\n",
      "Best value for C: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "clf_3 = LogisticRegression(penalty='l2',\n",
    "                           C=1.0,\n",
    "                           random_state=42,\n",
    "                           solver='saga',\n",
    "                           multi_class='ovr',\n",
    "                           max_iter=100,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True)\n",
    "\n",
    "param_grid = {'C':list(np.linspace(0.1,1.0,20))}            \n",
    "clf_3 = GridSearchCV(clf_3, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=True)\n",
    "clf_3.fit(X_train_svd, y_train_prep)\n",
    "best_c = round(clf_3.best_params_['C'],2)\n",
    "print('Best value for C: {}'.format(best_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 17 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit a model with the best C value\n",
    "clf_3 = LogisticRegression(penalty='l2',\n",
    "                           C=best_c,\n",
    "                           random_state=42,\n",
    "                           solver='saga',\n",
    "                           multi_class='ovr',\n",
    "                           max_iter=100,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True)\n",
    "\n",
    "clf_3.fit(X_train_svd, y_train_prep)\n",
    "test_predicted_labels_3 = clf_3.predict(X_test_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifer - SVD Dimensions = 100\n",
      "-------------\n",
      "\n",
      "Accuracy on test set: 0.735\n",
      "f_1 score (Weighted): 0.735\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with various f1 metrics\n",
    "f1_weighted = metrics.f1_score(y_test_prep, test_predicted_labels_3, average='weighted')\n",
    "accuracy = metrics.accuracy_score(y_test_prep, test_predicted_labels_3)\n",
    "    \n",
    "print('Logistic Regression Classifer - SVD Dimensions = {}'.format(dimensions))\n",
    "print('-------------\\n')\n",
    "print('Accuracy on test set: {:0.3f}'.format(accuracy))\n",
    "print('f_1 score (Weighted): {:0.3f}'.format(f1_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 1186\n",
      "True Positive: 1166\n",
      "False Negative: 434\n",
      "False Positive: 414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test_prep, test_predicted_labels_3)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_prep, test_predicted_labels_3).ravel()\n",
    "print(\"True Negative: {}\".format(tn))\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "print(\"False Negative: {}\".format(fn))\n",
    "print(\"False Positive: {}\".format(fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate Labeling Strategy\n",
    "Adapt from Jen's labeling notebook\n",
    "1. KBinsDiscretizer with strategy='kmeans'\n",
    "2. Try 3 classes (helpful, unhelpful, undetermined)\n",
    "3. Try training a model on helpful and unhelpful classes only; and on all 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
