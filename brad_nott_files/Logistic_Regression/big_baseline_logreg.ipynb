{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This is a \"scratchpad\" notebook of experiments and ideas. It helped to develop final ideas for the baseline logistic regression model using balanced groups, balanced classes, and clustering to assign class labels.\n",
    "\n",
    "It is disorganized...tread carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling Approaches/Results\n",
    "\n",
    "# 1. sampling wihtout replacement from all groups to match underrepresented class maximum (~13000)\n",
    "#    - 52000 train, 6000 test\n",
    "#    - f_1: .725\n",
    "\n",
    "# 2. take all the data and accept the imbalance\n",
    "\n",
    "# 3. sample 3 groups without replacement up to limit of neg_helpful (~81000)\n",
    "\n",
    "# 4. try a 3-label approach\n",
    "#    - All groups Jen made count for 1 and 0\n",
    "#    - All data we WERE leaving out, make that the third 'undetermined' class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "big_train = \"Data/labeled/labeled_training_set.csv\"\n",
    "train = pd.read_csv(big_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2659724, 15)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1981169\n",
       "1     678555\n",
       "Name: most_helpful, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of labels\n",
    "train['most_helpful'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load development data\n",
    "big_dev = \"Data/labeled/labeled_dev_set.csv\"\n",
    "dev = pd.read_csv(big_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314112, 15)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    227188\n",
       "1     86924\n",
       "Name: most_helpful, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of labels\n",
    "dev['most_helpful'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "big_test = \"Data/labeled/labeled_test_set.csv\"\n",
    "test = pd.read_csv(big_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313656, 15)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    226650\n",
       "1     87006\n",
       "Name: most_helpful, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of labels\n",
    "test['most_helpful'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10548803045692108"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape[0]/(train.shape[0]+test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup reviews without review content\n",
    "train.dropna(subset=['reviewText'],inplace=True)\n",
    "dev.dropna(subset=['reviewText'],inplace=True)\n",
    "test.dropna(subset=['reviewText'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 271443\n",
      "dev: 32445\n",
      "test: 32456\n"
     ]
    }
   ],
   "source": [
    "# How many reviews have exactly 0 helpful votes?\n",
    "print('train: {}'.format(sum(train.helpful_votes == 0)))\n",
    "print('dev: {}'.format(sum(dev.helpful_votes == 0)))\n",
    "print('test: {}'.format(sum(test.helpful_votes == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Format\n",
    "`overall` - customer supplied star-rating\n",
    "\n",
    "`most_helpful` - outcome variable. Reviews (positive or negative) with a annual HVAR value in the top quartile among reviews for the same book.\n",
    "\n",
    "`helpful_votes` - count variable for helpful votes\n",
    "\n",
    "**Testing Notes:**\n",
    "\n",
    "As a 2-class problem with balanced groups and no oversampling accuracy is approx. 73%\n",
    "\n",
    "- Using the top quartile threshold alone (no prepended/no bucketing, 100000 train/40000 test, tfidf 10000 features) - .619\n",
    "- Using the top quartile threshold + prepended/bucketing (52000 train/6000 test, tfidf no max features, balanced groups) - .719\n",
    "- Using the top quartile threshold + prepended/bucketing (104000 train/12000 test, tfidf no max features, balanced groups with 50% of neg_unhelpful is oversampled) - .72\n",
    "- Using the top quartile threshold + prepended/bucketing (104000 train/12000 test, tfidf 100k max features, balanced groups with 50% of neg_unhelpful is oversampled) - .722\n",
    "- Using the top quartile threshold + prepended/bucketing (104000 train/12000 test, tfidf 50k max features, balanced groups with 50% of neg_unhelpful is oversampled) - .724\n",
    "- Using the top quartile threshold + prepended/bucketing (104000 train/12000 test, tfidf 25k max features, balanced groups with 50% of neg_unhelpful is oversampled) - .722\n",
    "- Using the top quartile threshold + prepended/bucketing (104000 train/12000 test, tfidf 10k max features, balanced groups with 50% of neg_unhelpful is oversampled) - .721\n",
    "- Using the top quartile threshold + prepended/bucketing (208000 train/24000 test, tfidf 10k max features, balanced groups with 50% of neg_unhelpful is oversampled) - .723\n",
    "- Using the top quartile threshold + prepended/bucketing (208000 train/24000 test, tfidf 100k max features, balanced groups with 50% of neg_unhelpful is oversampled) - .723\n",
    "  - We aleready know this setup improves with more data\n",
    "  - Can we improve the result by incorporating a third class?\n",
    "- What about 3 classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_helpful: (81152, 15)\n",
      "neg_unhelpful: (13033, 15)\n",
      "pos_unhelpful: (121879, 15)\n",
      "pos_helpful: (316234, 15)\n"
     ]
    }
   ],
   "source": [
    "# How many examples of each group in training set?\n",
    "print('neg_helpful: {}'.format(train[(train.overall == 1) & (train.most_helpful == 1) & (train.helpful_votes != 0)].shape))\n",
    "print('neg_unhelpful: {}'.format(train[(train.overall == 1) & (train.most_helpful == 0) & (train.helpful_votes == 0)].shape))\n",
    "print('pos_unhelpful: {}'.format(train[(train.overall == 5) & (train.most_helpful == 0) & (train.helpful_votes == 0)].shape))\n",
    "print('pos_helpful: {}'.format(train[(train.overall == 5) & (train.most_helpful == 1) & (train.helpful_votes != 0)].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532298"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total edge classes\n",
    "81152+13033+121879+316234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2127125"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples remain? (potentially \"undetermined\")\n",
    "# - for a 3-class problem these will be labeled 'undetermined' and randomly sampled\n",
    "train.shape[0] - 532298"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_helpful: (10061, 15)\n",
      "neg_unhelpful: (1504, 15)\n",
      "pos_unhelpful: (14786, 15)\n",
      "pos_helpful: (40648, 15)\n"
     ]
    }
   ],
   "source": [
    "# How many examples of each group in dev set?\n",
    "print('neg_helpful: {}'.format(dev[(dev.overall == 1) & (dev.most_helpful == 1) & (dev.helpful_votes != 0)].shape))\n",
    "print('neg_unhelpful: {}'.format(dev[(dev.overall == 1) & (dev.most_helpful == 0) & (dev.helpful_votes == 0)].shape))\n",
    "print('pos_unhelpful: {}'.format(dev[(dev.overall == 5) & (dev.most_helpful == 0) & (dev.helpful_votes == 0)].shape))\n",
    "print('pos_helpful: {}'.format(dev[(dev.overall == 5) & (dev.most_helpful == 1) & (dev.helpful_votes != 0)].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_helpful: (10500, 15)\n",
      "neg_unhelpful: (1533, 15)\n",
      "pos_unhelpful: (14569, 15)\n",
      "pos_helpful: (40090, 15)\n"
     ]
    }
   ],
   "source": [
    "# How many examples of each group in test set?\n",
    "print('neg_helpful: {}'.format(test[(test.overall == 1) & (test.most_helpful == 1) & (test.helpful_votes != 0)].shape))\n",
    "print('neg_unhelpful: {}'.format(test[(test.overall == 1) & (test.most_helpful == 0) & (test.helpful_votes == 0)].shape))\n",
    "print('pos_unhelpful: {}'.format(test[(test.overall == 5) & (test.most_helpful == 0) & (test.helpful_votes == 0)].shape))\n",
    "print('pos_helpful: {}'.format(test[(test.overall == 5) & (test.most_helpful == 1) & (test.helpful_votes != 0)].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Training Set\n",
    "# Below I sample to have equal amounts of pos/neg reviews and equal amounts of top-quartile-HVAR vs 0 helpful votes\n",
    "\n",
    "num_per_condition = 13000\n",
    "repl=False\n",
    "\n",
    "train_neg_helpful = train[(train.overall == 1) & (train.most_helpful == 1) & (train.helpful_votes != 0)].sample(num_per_condition, replace=repl)\n",
    "train_neg_unhelpful = train[(train.overall == 1) & (train.most_helpful == 0) & (train.helpful_votes == 0)].sample(num_per_condition, replace=repl)\n",
    "train_pos_unhelpful = train[(train.overall == 5) & (train.most_helpful == 0) & (train.helpful_votes == 0)].sample(num_per_condition, replace=repl)\n",
    "train_pos_helpful = train[(train.overall == 5) & (train.most_helpful == 1) & (train.helpful_votes != 0)].sample(num_per_condition, replace=repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Dev Set\n",
    "# 1500 = no oversampling\n",
    "\n",
    "num_per_condition = 1500\n",
    "repl=False\n",
    "\n",
    "dev_neg_helpful = dev[(dev.overall == 1) & (dev.most_helpful == 1) & (dev.helpful_votes != 0)].sample(num_per_condition, replace=repl)\n",
    "dev_neg_unhelpful = dev[(dev.overall == 1) & (dev.most_helpful == 0) & (dev.helpful_votes == 0)].sample(num_per_condition, replace=repl)\n",
    "dev_pos_unhelpful = dev[(dev.overall == 5) & (dev.most_helpful == 0) & (dev.helpful_votes == 0)].sample(num_per_condition, replace=repl)\n",
    "dev_pos_helpful = dev[(dev.overall == 5) & (dev.most_helpful == 1) & (dev.helpful_votes != 0)].sample(num_per_condition, replace=repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Test Set\n",
    "# 1500 = no oversampling\n",
    "\n",
    "num_per_condition = 1500\n",
    "repl=False\n",
    "\n",
    "test_neg_helpful = test[(test.overall == 1) & (test.most_helpful == 1) & (test.helpful_votes != 0)].sample(num_per_condition, replace=repl)\n",
    "test_neg_unhelpful = test[(test.overall == 1) & (test.most_helpful == 0) & (test.helpful_votes == 0)].sample(num_per_condition, replace=repl)\n",
    "test_pos_unhelpful = test[(test.overall == 5) & (test.most_helpful == 0) & (test.helpful_votes == 0)].sample(num_per_condition, replace=repl)\n",
    "test_pos_helpful = test[(test.overall == 5) & (test.most_helpful == 1) & (test.helpful_votes != 0)].sample(num_per_condition, replace=repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepend training set\n",
    "\n",
    "train_neg_helpful['prepReviewText'] = train_neg_helpful.apply(lambda x: 'WORST ' + x.reviewText,axis = 1)\n",
    "train_neg_unhelpful['prepReviewText'] = train_neg_unhelpful.apply(lambda x: 'WORST ' + x.reviewText,axis = 1)\n",
    "train_pos_unhelpful['prepReviewText'] = train_pos_unhelpful.apply(lambda x: 'BEST ' + x.reviewText,axis = 1)\n",
    "train_pos_helpful['prepReviewText'] = train_pos_helpful.apply(lambda x: 'BEST ' + x.reviewText,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepend dev set\n",
    "\n",
    "dev_neg_helpful['prepReviewText'] = dev_neg_helpful.apply(lambda x: 'WORST ' + x.reviewText,axis = 1)\n",
    "dev_neg_unhelpful['prepReviewText'] = dev_neg_unhelpful.apply(lambda x: 'WORST ' + x.reviewText,axis = 1)\n",
    "dev_pos_unhelpful['prepReviewText'] = dev_pos_unhelpful.apply(lambda x: 'BEST ' + x.reviewText,axis = 1)\n",
    "dev_pos_helpful['prepReviewText'] = dev_pos_helpful.apply(lambda x: 'BEST ' + x.reviewText,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepend test set\n",
    "\n",
    "test_neg_helpful['prepReviewText'] = test_neg_helpful.apply(lambda x: 'WORST ' + x.reviewText,axis = 1)\n",
    "test_neg_unhelpful['prepReviewText'] = test_neg_unhelpful.apply(lambda x: 'WORST ' + x.reviewText,axis = 1)\n",
    "test_pos_unhelpful['prepReviewText'] = test_pos_unhelpful.apply(lambda x: 'BEST ' + x.reviewText,axis = 1)\n",
    "test_pos_helpful['prepReviewText'] = test_pos_helpful.apply(lambda x: 'BEST ' + x.reviewText,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training dataset is now 52000 reviews.\n"
     ]
    }
   ],
   "source": [
    "# Assemble training set\n",
    "\n",
    "stratdf_train = train_neg_helpful.append(train_neg_unhelpful, ignore_index=True)\n",
    "stratdf_train = stratdf_train.append(train_pos_unhelpful, ignore_index=True)\n",
    "stratdf_train = stratdf_train.append(train_pos_helpful, ignore_index=True)\n",
    "print(f\"Our training dataset is now {stratdf_train.shape[0]} reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our development dataset is now 6000 reviews.\n"
     ]
    }
   ],
   "source": [
    "# Assemble dev set\n",
    "\n",
    "stratdf_dev = dev_neg_helpful.append(dev_neg_unhelpful, ignore_index=True)\n",
    "stratdf_dev = stratdf_dev.append(dev_pos_unhelpful, ignore_index=True)\n",
    "stratdf_dev = stratdf_dev.append(dev_pos_helpful, ignore_index=True)\n",
    "print(f\"Our development dataset is now {stratdf_dev.shape[0]} reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test dataset is now 6000 reviews.\n"
     ]
    }
   ],
   "source": [
    "# Assemble test set\n",
    "\n",
    "stratdf_test = test_neg_helpful.append(test_neg_unhelpful, ignore_index=True)\n",
    "stratdf_test = stratdf_test.append(test_pos_unhelpful, ignore_index=True)\n",
    "stratdf_test = stratdf_test.append(test_pos_helpful, ignore_index=True)\n",
    "print(f\"Our test dataset is now {stratdf_test.shape[0]} reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10344827586206896"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stratdf_test.shape[0]/(stratdf_test.shape[0]+stratdf_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_prep = shuffle(stratdf_train,random_state=42)[['prepReviewText','overall','most_helpful']]\n",
    "df_dev_prep = shuffle(stratdf_dev,random_state=42)[['prepReviewText','overall','most_helpful']]\n",
    "df_test_prep = shuffle(stratdf_test,random_state=42)[['prepReviewText','overall','most_helpful']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_prep.to_csv('train_prep.csv')\n",
    "df_dev_prep.to_csv('dev_prep.csv')\n",
    "df_test_prep.to_csv('test_prep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep = df_train_prep['prepReviewText']\n",
    "X_dev_prep = df_dev_prep['prepReviewText']\n",
    "X_test_prep = df_test_prep['prepReviewText']\n",
    "\n",
    "y_train_prep = df_train_prep['most_helpful']\n",
    "y_dev_prep = df_dev_prep['most_helpful']\n",
    "y_test_prep = df_test_prep['most_helpful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count: 1786688\n"
     ]
    }
   ],
   "source": [
    "# Transform text examples\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                             #tokenizer=Tokenizer,\n",
    "                             analyzer='word',\n",
    "                             stop_words=None,\n",
    "                             token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'|\\*|\\-|\\;|\\:|\\,|\\.\",\n",
    "                             ngram_range=(1,2),\n",
    "                             max_features=None)\n",
    "\n",
    "X_train_prep_vec = vectorizer.fit_transform(X_train_prep)\n",
    "X_dev_prep_vec = vectorizer.transform(X_dev_prep)\n",
    "\n",
    "print(\"Token Count: {}\".format(len(vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 20 epochs took 8 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=42, solver='saga', tol=0.0001,\n",
       "          verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more than 2 classes...multinomial\n",
    "\n",
    "# binary problem\n",
    "\n",
    "# The SAGA solver is a variant of SAG that also supports the non-smooth penalty=l1 option (i.e. L1 Regularization).\n",
    "# This is therefore the solver of choice for sparse multinomial logistic regression and it’s also suitable very Large datasets.\n",
    "\n",
    "# C = inverse of regularization strength; pos float; smaller = stronger regularization\n",
    "\n",
    "clf = LogisticRegression(penalty='l2',\n",
    "                         C=1.0,\n",
    "                         random_state=42,\n",
    "                         solver='saga',\n",
    "                         multi_class='ovr',\n",
    "                         max_iter=100,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_train_prep_vec, y_train_prep)\n",
    "#clf.fit(X_train_svd, y_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_predicted_labels = clf.predict(X_dev_svd)\n",
    "dev_predicted_labels = clf.predict(X_dev_prep_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifer\n",
      "-------------\n",
      "\n",
      "Accuracy on test set: 0.730\n",
      "f_1 score (Weighted): 0.730\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with various f1 metrics\n",
    "f1_weighted = metrics.f1_score(y_dev_prep, dev_predicted_labels, average='weighted')\n",
    "accuracy = metrics.accuracy_score(y_dev_prep, dev_predicted_labels)\n",
    "    \n",
    "print('Logistic Regression Classifer')\n",
    "print('-------------\\n')\n",
    "print('Accuracy on test set: {:0.3f}'.format(accuracy))\n",
    "print('f_1 score (Weighted): {:0.3f}'.format(f1_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifer - Test Set\n",
      "-------------\n",
      "\n",
      "Accuracy on test set: 0.719\n",
      "f_1 score (Weighted): 0.719\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "\n",
    "X_test_prep_vec = vectorizer.transform(X_test_prep)\n",
    "test_predicted_labels = clf.predict(X_test_prep_vec)\n",
    "\n",
    "# Evaluate with various f1 metrics\n",
    "f1_weighted = metrics.f1_score(y_test_prep, test_predicted_labels, average='weighted')\n",
    "accuracy = metrics.accuracy_score(y_test_prep, test_predicted_labels)\n",
    "    \n",
    "print('Logistic Regression Classifer - Test Set')\n",
    "print('-------------\\n')\n",
    "print('Accuracy on test set: {:0.3f}'.format(accuracy))\n",
    "print('f_1 score (Weighted): {:0.3f}'.format(f1_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 20 epochs took 4 seconds\n",
      "Best value for C: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    4.0s finished\n"
     ]
    }
   ],
   "source": [
    "clf_2 = LogisticRegression(penalty='l2',\n",
    "                           C=1.0,\n",
    "                           random_state=42,\n",
    "                           solver='saga',\n",
    "                           multi_class='ovr',\n",
    "                           max_iter=100,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True)\n",
    "\n",
    "param_grid = {'C':list(np.linspace(0.1,1.0,10))}            \n",
    "clf_2 = GridSearchCV(clf_2, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=True)\n",
    "clf_2.fit(X_train_prep_vec, y_train_prep)\n",
    "best_c = round(clf_2.best_params_['C'],2)\n",
    "print('Best value for C: {}'.format(best_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 20 epochs took 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit a model with the best C value\n",
    "clf_2 = LogisticRegression(penalty='l2',\n",
    "                           C=best_c,\n",
    "                           random_state=42,\n",
    "                           solver='saga',\n",
    "                           multi_class='ovr',\n",
    "                           max_iter=100,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True)\n",
    "\n",
    "clf_2.fit(X_train_prep_vec, y_train_prep)\n",
    "dev_predicted_labels_2 = clf_2.predict(X_dev_prep_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifer\n",
      "-------------\n",
      "\n",
      "Accuracy on test set: 0.729\n",
      "f_1 score (Weighted): 0.729\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with various f1 metrics\n",
    "f1_weighted = metrics.f1_score(y_dev_prep, dev_predicted_labels_2, average='weighted')\n",
    "accuracy = metrics.accuracy_score(y_dev_prep, dev_predicted_labels_2)\n",
    "    \n",
    "print('Logistic Regression Classifer')\n",
    "print('-------------\\n')\n",
    "print('Accuracy on test set: {:0.3f}'.format(accuracy))\n",
    "print('f_1 score (Weighted): {:0.3f}'.format(f1_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 2208\n",
      "True Positive: 2150\n",
      "False Negative: 850\n",
      "False Positive: 792\n"
     ]
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_dev_prep, dev_predicted_labels_2)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_dev_prep, dev_predicted_labels_2).ravel()\n",
    "print(\"True Negative: {}\".format(tn))\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "print(\"False Negative: {}\".format(fn))\n",
    "print(\"False Positive: {}\".format(fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make it multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'class' column to training data\n",
    "# - Initially all entries are 'undetermined'\n",
    "\n",
    "train['class'] = 'undetermined'\n",
    "dev['class'] = 'undetermined'\n",
    "test['class'] = 'undetermined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through and change the label according to conditions\n",
    "\n",
    "train.loc[(train.overall == 1) & (train.most_helpful == 1) & (train.helpful_votes != 0), 'class'] = 'neg_helpful'\n",
    "train.loc[(train.overall == 1) & (train.most_helpful == 0) & (train.helpful_votes == 0), 'class'] = 'neg_unhelpful'\n",
    "train.loc[(train.overall == 5) & (train.most_helpful == 0) & (train.helpful_votes == 0), 'class'] = 'pos_unhelpful'\n",
    "train.loc[(train.overall == 5) & (train.most_helpful == 1) & (train.helpful_votes != 0), 'class'] = 'pos_helpful'\n",
    "\n",
    "dev.loc[(dev.overall == 1) & (dev.most_helpful == 1) & (dev.helpful_votes != 0), 'class'] = 'neg_helpful'\n",
    "dev.loc[(dev.overall == 1) & (dev.most_helpful == 0) & (dev.helpful_votes == 0), 'class'] = 'neg_unhelpful'\n",
    "dev.loc[(dev.overall == 5) & (dev.most_helpful == 0) & (dev.helpful_votes == 0), 'class'] = 'pos_unhelpful'\n",
    "dev.loc[(dev.overall == 5) & (dev.most_helpful == 1) & (dev.helpful_votes != 0), 'class'] = 'pos_helpful'\n",
    "\n",
    "test.loc[(test.overall == 1) & (test.most_helpful == 1) & (test.helpful_votes != 0), 'class'] = 'neg_helpful'\n",
    "test.loc[(test.overall == 1) & (test.most_helpful == 0) & (test.helpful_votes == 0), 'class'] = 'neg_unhelpful'\n",
    "test.loc[(test.overall == 5) & (test.most_helpful == 0) & (test.helpful_votes == 0), 'class'] = 'pos_unhelpful'\n",
    "test.loc[(test.overall == 5) & (test.most_helpful == 1) & (test.helpful_votes != 0), 'class'] = 'pos_helpful'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undetermined     2127125\n",
       "pos_helpful       316234\n",
       "pos_unhelpful     121879\n",
       "neg_helpful        81152\n",
       "neg_unhelpful      13033\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undetermined     247081\n",
       "pos_helpful       40648\n",
       "pos_unhelpful     14786\n",
       "neg_helpful       10061\n",
       "neg_unhelpful      1504\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undetermined     246910\n",
       "pos_helpful       40090\n",
       "pos_unhelpful     14569\n",
       "neg_helpful       10500\n",
       "neg_unhelpful      1533\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two approaches\n",
    "\n",
    "# 1. 5-class classification (65,000 total reviews)\n",
    "#    Sample 13,000 reviews from each of the new categories\n",
    "\n",
    "\n",
    "\n",
    "# 2. 3-class classification (78,000 total reviews)\n",
    "#    Sample:\n",
    "#       pos_helpful + pos_unhelpful = 13,000 + 13,000 = 26,000 helpful\n",
    "#       neg_helpful + neg_unhelpful = 13,000 + 13,000 = 26,000 unhelpful\n",
    "#       undetermined                = 26,000 undetermined\n",
    "\n",
    "num_per_condition = 13000\n",
    "\n",
    "# mc = multi-class\n",
    "\n",
    "# Sample multi-class examples from training set\n",
    "mc_train_pos_helpful = train[train['class'] == 'pos_helpful'].sample(13000, replace=False)\n",
    "mc_train_pos_unhelpful = train[train['class'] == 'pos_unhelpful'].sample(13000, replace=False)\n",
    "mc_train_neg_helpful = train[train['class'] == 'neg_helpful'].sample(13000, replace=False)\n",
    "mc_train_neg_unhelpful = train[train['class'] == 'neg_unhelpful'].sample(13000, replace=False)\n",
    "\n",
    "mc5_train_undetermined = train[train['class'] == 'undetermined'].sample(13000, replace=False)\n",
    "mc3_train_undetermined = train[train['class'] == 'undetermined'].sample(26000, replace=False)\n",
    "\n",
    "# Sample multi-class examples from development set\n",
    "mc_dev_pos_helpful = dev[dev['class'] == 'pos_helpful'].sample(1500, replace=False)\n",
    "mc_dev_pos_unhelpful = dev[dev['class'] == 'pos_unhelpful'].sample(1500, replace=False)\n",
    "mc_dev_neg_helpful = dev[dev['class'] == 'neg_helpful'].sample(1500, replace=False)\n",
    "mc_dev_neg_unhelpful = dev[dev['class'] == 'neg_unhelpful'].sample(1500, replace=False)\n",
    "\n",
    "mc5_dev_undetermined = dev[dev['class'] == 'undetermined'].sample(1500, replace=False)\n",
    "mc3_dev_undetermined = dev[dev['class'] == 'undetermined'].sample(3000, replace=False)\n",
    "\n",
    "\n",
    "\n",
    "# nothing is prepended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>review_age_days</th>\n",
       "      <th>annual_HVAR</th>\n",
       "      <th>book_num_reviews</th>\n",
       "      <th>std_HVAR</th>\n",
       "      <th>top_quartile_HVAR</th>\n",
       "      <th>most_helpful</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>963554</th>\n",
       "      <td>145161747X</td>\n",
       "      <td>5</td>\n",
       "      <td>In 70 C.E. Jerusalem fell to the Romans and th...</td>\n",
       "      <td>2011-09-20</td>\n",
       "      <td>A3GK1O5S6188AJ</td>\n",
       "      <td>Amy Willingham</td>\n",
       "      <td>4 Stories Separate Yet Connected</td>\n",
       "      <td>1316476800</td>\n",
       "      <td>11</td>\n",
       "      <td>1037</td>\n",
       "      <td>3.871745</td>\n",
       "      <td>84</td>\n",
       "      <td>26.896178</td>\n",
       "      <td>2.159243</td>\n",
       "      <td>1</td>\n",
       "      <td>pos_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44179</th>\n",
       "      <td>0060987103</td>\n",
       "      <td>5</td>\n",
       "      <td>I've owned this book for almost 3yrs and now j...</td>\n",
       "      <td>2003-11-16</td>\n",
       "      <td>AX3WJZLFQQRCT</td>\n",
       "      <td>R. M. Ettinger \"rme1963\"</td>\n",
       "      <td>Wonderfully Done!</td>\n",
       "      <td>1068940800</td>\n",
       "      <td>50</td>\n",
       "      <td>3902</td>\n",
       "      <td>4.677089</td>\n",
       "      <td>471</td>\n",
       "      <td>0.921940</td>\n",
       "      <td>0.707367</td>\n",
       "      <td>1</td>\n",
       "      <td>pos_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376498</th>\n",
       "      <td>0385720564</td>\n",
       "      <td>5</td>\n",
       "      <td>Though it lacks the wide opinion that William ...</td>\n",
       "      <td>2006-02-10</td>\n",
       "      <td>AFVQZQ8PW0L</td>\n",
       "      <td>Harriet Klausner</td>\n",
       "      <td>Terrific  biography</td>\n",
       "      <td>1139529600</td>\n",
       "      <td>15</td>\n",
       "      <td>3085</td>\n",
       "      <td>1.774716</td>\n",
       "      <td>15</td>\n",
       "      <td>0.473053</td>\n",
       "      <td>0.837270</td>\n",
       "      <td>1</td>\n",
       "      <td>pos_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327182</th>\n",
       "      <td>0373860056</td>\n",
       "      <td>5</td>\n",
       "      <td>I have been a fan of Adrianne Byrd's writing f...</td>\n",
       "      <td>2007-01-28</td>\n",
       "      <td>A1L0PD6BRHDD31</td>\n",
       "      <td>Reader Woman \"The Book Diva\"</td>\n",
       "      <td>If only collisions where so sexy and so much f...</td>\n",
       "      <td>1169942400</td>\n",
       "      <td>6</td>\n",
       "      <td>2733</td>\n",
       "      <td>0.801317</td>\n",
       "      <td>5</td>\n",
       "      <td>0.288584</td>\n",
       "      <td>0.286162</td>\n",
       "      <td>1</td>\n",
       "      <td>pos_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556652</th>\n",
       "      <td>0615547753</td>\n",
       "      <td>5</td>\n",
       "      <td>I have been so lost trying to figure out how t...</td>\n",
       "      <td>2012-10-15</td>\n",
       "      <td>A3FKSL93FIX0BZ</td>\n",
       "      <td>K. Bosworth</td>\n",
       "      <td>Excellent, well written book on gastroparesis</td>\n",
       "      <td>1350259200</td>\n",
       "      <td>8</td>\n",
       "      <td>646</td>\n",
       "      <td>4.520124</td>\n",
       "      <td>10</td>\n",
       "      <td>1.467419</td>\n",
       "      <td>1.640382</td>\n",
       "      <td>1</td>\n",
       "      <td>pos_helpful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin  overall  \\\n",
       "963554  145161747X        5   \n",
       "44179   0060987103        5   \n",
       "376498  0385720564        5   \n",
       "327182  0373860056        5   \n",
       "556652  0615547753        5   \n",
       "\n",
       "                                               reviewText  reviewTime  \\\n",
       "963554  In 70 C.E. Jerusalem fell to the Romans and th...  2011-09-20   \n",
       "44179   I've owned this book for almost 3yrs and now j...  2003-11-16   \n",
       "376498  Though it lacks the wide opinion that William ...  2006-02-10   \n",
       "327182  I have been a fan of Adrianne Byrd's writing f...  2007-01-28   \n",
       "556652  I have been so lost trying to figure out how t...  2012-10-15   \n",
       "\n",
       "            reviewerID                  reviewerName  \\\n",
       "963554  A3GK1O5S6188AJ                Amy Willingham   \n",
       "44179    AX3WJZLFQQRCT      R. M. Ettinger \"rme1963\"   \n",
       "376498     AFVQZQ8PW0L              Harriet Klausner   \n",
       "327182  A1L0PD6BRHDD31  Reader Woman \"The Book Diva\"   \n",
       "556652  A3FKSL93FIX0BZ                   K. Bosworth   \n",
       "\n",
       "                                                  summary  unixReviewTime  \\\n",
       "963554                   4 Stories Separate Yet Connected      1316476800   \n",
       "44179                                   Wonderfully Done!      1068940800   \n",
       "376498                                Terrific  biography      1139529600   \n",
       "327182  If only collisions where so sexy and so much f...      1169942400   \n",
       "556652      Excellent, well written book on gastroparesis      1350259200   \n",
       "\n",
       "        helpful_votes  review_age_days  annual_HVAR  book_num_reviews  \\\n",
       "963554             11             1037     3.871745                84   \n",
       "44179              50             3902     4.677089               471   \n",
       "376498             15             3085     1.774716                15   \n",
       "327182              6             2733     0.801317                 5   \n",
       "556652              8              646     4.520124                10   \n",
       "\n",
       "         std_HVAR  top_quartile_HVAR  most_helpful        class  \n",
       "963554  26.896178           2.159243             1  pos_helpful  \n",
       "44179    0.921940           0.707367             1  pos_helpful  \n",
       "376498   0.473053           0.837270             1  pos_helpful  \n",
       "327182   0.288584           0.286162             1  pos_helpful  \n",
       "556652   1.467419           1.640382             1  pos_helpful  "
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_train_pos_helpful.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our 5-class training dataset is now 65000 reviews.\n"
     ]
    }
   ],
   "source": [
    "# Assemble 5-class training set\n",
    "\n",
    "mc5_train = mc_train_neg_helpful.append(mc_train_neg_unhelpful, ignore_index=True)\n",
    "mc5_train = mc5_train.append(mc_train_pos_unhelpful, ignore_index=True)\n",
    "mc5_train = mc5_train.append(mc_train_pos_helpful, ignore_index=True)\n",
    "mc5_train = mc5_train.append(mc5_train_undetermined, ignore_index=True)\n",
    "print(f\"Our 5-class training dataset is now {mc5_train.shape[0]} reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>review_age_days</th>\n",
       "      <th>annual_HVAR</th>\n",
       "      <th>book_num_reviews</th>\n",
       "      <th>std_HVAR</th>\n",
       "      <th>top_quartile_HVAR</th>\n",
       "      <th>most_helpful</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0451239113</td>\n",
       "      <td>1</td>\n",
       "      <td>Parker's writings have dwindled to the point o...</td>\n",
       "      <td>2012-06-09</td>\n",
       "      <td>AN9V3LI0G85K5</td>\n",
       "      <td>Ron cz</td>\n",
       "      <td>Parker's Lost It!!!!!!!!!!</td>\n",
       "      <td>1339200000</td>\n",
       "      <td>6</td>\n",
       "      <td>774</td>\n",
       "      <td>2.829457</td>\n",
       "      <td>16</td>\n",
       "      <td>1.636546</td>\n",
       "      <td>1.781095</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0026045702</td>\n",
       "      <td>1</td>\n",
       "      <td>The original version of Joy is a strong conten...</td>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>A2K33VWYQC9C2W</td>\n",
       "      <td>jerry i h</td>\n",
       "      <td>Worthless Garbage</td>\n",
       "      <td>1118880000</td>\n",
       "      <td>23</td>\n",
       "      <td>3324</td>\n",
       "      <td>2.525572</td>\n",
       "      <td>102</td>\n",
       "      <td>2.269745</td>\n",
       "      <td>0.941812</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0380818612</td>\n",
       "      <td>1</td>\n",
       "      <td>I struggled to identify with her main characte...</td>\n",
       "      <td>2010-02-02</td>\n",
       "      <td>A3NY49QVQJQK7P</td>\n",
       "      <td>Kevin Watt \"I know that poetry is indispensab...</td>\n",
       "      <td>Awful.  Not up to her usual awesomeness.  Slow...</td>\n",
       "      <td>1265068800</td>\n",
       "      <td>4</td>\n",
       "      <td>1632</td>\n",
       "      <td>0.894608</td>\n",
       "      <td>57</td>\n",
       "      <td>1.681225</td>\n",
       "      <td>0.731463</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0057PFWDI</td>\n",
       "      <td>1</td>\n",
       "      <td>I found myself rolling my eyes and laughing wh...</td>\n",
       "      <td>2013-03-19</td>\n",
       "      <td>A1GS6FEGHFNIG</td>\n",
       "      <td>Deana</td>\n",
       "      <td>Hmmm</td>\n",
       "      <td>1363651200</td>\n",
       "      <td>3</td>\n",
       "      <td>491</td>\n",
       "      <td>2.230143</td>\n",
       "      <td>35</td>\n",
       "      <td>0.777522</td>\n",
       "      <td>0.937360</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0613171373</td>\n",
       "      <td>1</td>\n",
       "      <td>He was severely abused, (insert graphic detail...</td>\n",
       "      <td>2009-08-18</td>\n",
       "      <td>A3HQD8NJZLA1MO</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>This is a perfect candidate for a book burning</td>\n",
       "      <td>1250553600</td>\n",
       "      <td>6</td>\n",
       "      <td>1800</td>\n",
       "      <td>1.216667</td>\n",
       "      <td>171</td>\n",
       "      <td>1.524067</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  0451239113        1  Parker's writings have dwindled to the point o...   \n",
       "1  0026045702        1  The original version of Joy is a strong conten...   \n",
       "2  0380818612        1  I struggled to identify with her main characte...   \n",
       "3  B0057PFWDI        1  I found myself rolling my eyes and laughing wh...   \n",
       "4  0613171373        1  He was severely abused, (insert graphic detail...   \n",
       "\n",
       "   reviewTime      reviewerID  \\\n",
       "0  2012-06-09   AN9V3LI0G85K5   \n",
       "1  2005-06-16  A2K33VWYQC9C2W   \n",
       "2  2010-02-02  A3NY49QVQJQK7P   \n",
       "3  2013-03-19   A1GS6FEGHFNIG   \n",
       "4  2009-08-18  A3HQD8NJZLA1MO   \n",
       "\n",
       "                                       reviewerName  \\\n",
       "0                                            Ron cz   \n",
       "1                                         jerry i h   \n",
       "2  Kevin Watt \"I know that poetry is indispensab...   \n",
       "3                                             Deana   \n",
       "4                                   Amazon Customer   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                         Parker's Lost It!!!!!!!!!!      1339200000   \n",
       "1                                  Worthless Garbage      1118880000   \n",
       "2  Awful.  Not up to her usual awesomeness.  Slow...      1265068800   \n",
       "3                                               Hmmm      1363651200   \n",
       "4     This is a perfect candidate for a book burning      1250553600   \n",
       "\n",
       "   helpful_votes  review_age_days  annual_HVAR  book_num_reviews  std_HVAR  \\\n",
       "0              6              774     2.829457                16  1.636546   \n",
       "1             23             3324     2.525572               102  2.269745   \n",
       "2              4             1632     0.894608                57  1.681225   \n",
       "3              3              491     2.230143                35  0.777522   \n",
       "4              6             1800     1.216667               171  1.524067   \n",
       "\n",
       "   top_quartile_HVAR  most_helpful        class  \n",
       "0           1.781095             1  neg_helpful  \n",
       "1           0.941812             1  neg_helpful  \n",
       "2           0.731463             1  neg_helpful  \n",
       "3           0.937360             1  neg_helpful  \n",
       "4           0.480200             1  neg_helpful  "
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc5_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undetermined     13000\n",
       "neg_helpful      13000\n",
       "neg_unhelpful    13000\n",
       "pos_unhelpful    13000\n",
       "pos_helpful      13000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc5_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our 3-class training dataset is now 78000 reviews.\n"
     ]
    }
   ],
   "source": [
    "# Assemble 3-class training set\n",
    "\n",
    "mc3_train = mc_train_neg_helpful.append(mc_train_neg_unhelpful, ignore_index=True)\n",
    "mc3_train = mc3_train.append(mc_train_pos_unhelpful, ignore_index=True)\n",
    "mc3_train = mc3_train.append(mc_train_pos_helpful, ignore_index=True)\n",
    "mc3_train = mc3_train.append(mc3_train_undetermined, ignore_index=True)\n",
    "print(f\"Our 3-class training dataset is now {mc3_train.shape[0]} reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>review_age_days</th>\n",
       "      <th>annual_HVAR</th>\n",
       "      <th>book_num_reviews</th>\n",
       "      <th>std_HVAR</th>\n",
       "      <th>top_quartile_HVAR</th>\n",
       "      <th>most_helpful</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0451239113</td>\n",
       "      <td>1</td>\n",
       "      <td>Parker's writings have dwindled to the point o...</td>\n",
       "      <td>2012-06-09</td>\n",
       "      <td>AN9V3LI0G85K5</td>\n",
       "      <td>Ron cz</td>\n",
       "      <td>Parker's Lost It!!!!!!!!!!</td>\n",
       "      <td>1339200000</td>\n",
       "      <td>6</td>\n",
       "      <td>774</td>\n",
       "      <td>2.829457</td>\n",
       "      <td>16</td>\n",
       "      <td>1.636546</td>\n",
       "      <td>1.781095</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0026045702</td>\n",
       "      <td>1</td>\n",
       "      <td>The original version of Joy is a strong conten...</td>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>A2K33VWYQC9C2W</td>\n",
       "      <td>jerry i h</td>\n",
       "      <td>Worthless Garbage</td>\n",
       "      <td>1118880000</td>\n",
       "      <td>23</td>\n",
       "      <td>3324</td>\n",
       "      <td>2.525572</td>\n",
       "      <td>102</td>\n",
       "      <td>2.269745</td>\n",
       "      <td>0.941812</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0380818612</td>\n",
       "      <td>1</td>\n",
       "      <td>I struggled to identify with her main characte...</td>\n",
       "      <td>2010-02-02</td>\n",
       "      <td>A3NY49QVQJQK7P</td>\n",
       "      <td>Kevin Watt \"I know that poetry is indispensab...</td>\n",
       "      <td>Awful.  Not up to her usual awesomeness.  Slow...</td>\n",
       "      <td>1265068800</td>\n",
       "      <td>4</td>\n",
       "      <td>1632</td>\n",
       "      <td>0.894608</td>\n",
       "      <td>57</td>\n",
       "      <td>1.681225</td>\n",
       "      <td>0.731463</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0057PFWDI</td>\n",
       "      <td>1</td>\n",
       "      <td>I found myself rolling my eyes and laughing wh...</td>\n",
       "      <td>2013-03-19</td>\n",
       "      <td>A1GS6FEGHFNIG</td>\n",
       "      <td>Deana</td>\n",
       "      <td>Hmmm</td>\n",
       "      <td>1363651200</td>\n",
       "      <td>3</td>\n",
       "      <td>491</td>\n",
       "      <td>2.230143</td>\n",
       "      <td>35</td>\n",
       "      <td>0.777522</td>\n",
       "      <td>0.937360</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0613171373</td>\n",
       "      <td>1</td>\n",
       "      <td>He was severely abused, (insert graphic detail...</td>\n",
       "      <td>2009-08-18</td>\n",
       "      <td>A3HQD8NJZLA1MO</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>This is a perfect candidate for a book burning</td>\n",
       "      <td>1250553600</td>\n",
       "      <td>6</td>\n",
       "      <td>1800</td>\n",
       "      <td>1.216667</td>\n",
       "      <td>171</td>\n",
       "      <td>1.524067</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  0451239113        1  Parker's writings have dwindled to the point o...   \n",
       "1  0026045702        1  The original version of Joy is a strong conten...   \n",
       "2  0380818612        1  I struggled to identify with her main characte...   \n",
       "3  B0057PFWDI        1  I found myself rolling my eyes and laughing wh...   \n",
       "4  0613171373        1  He was severely abused, (insert graphic detail...   \n",
       "\n",
       "   reviewTime      reviewerID  \\\n",
       "0  2012-06-09   AN9V3LI0G85K5   \n",
       "1  2005-06-16  A2K33VWYQC9C2W   \n",
       "2  2010-02-02  A3NY49QVQJQK7P   \n",
       "3  2013-03-19   A1GS6FEGHFNIG   \n",
       "4  2009-08-18  A3HQD8NJZLA1MO   \n",
       "\n",
       "                                       reviewerName  \\\n",
       "0                                            Ron cz   \n",
       "1                                         jerry i h   \n",
       "2  Kevin Watt \"I know that poetry is indispensab...   \n",
       "3                                             Deana   \n",
       "4                                   Amazon Customer   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                         Parker's Lost It!!!!!!!!!!      1339200000   \n",
       "1                                  Worthless Garbage      1118880000   \n",
       "2  Awful.  Not up to her usual awesomeness.  Slow...      1265068800   \n",
       "3                                               Hmmm      1363651200   \n",
       "4     This is a perfect candidate for a book burning      1250553600   \n",
       "\n",
       "   helpful_votes  review_age_days  annual_HVAR  book_num_reviews  std_HVAR  \\\n",
       "0              6              774     2.829457                16  1.636546   \n",
       "1             23             3324     2.525572               102  2.269745   \n",
       "2              4             1632     0.894608                57  1.681225   \n",
       "3              3              491     2.230143                35  0.777522   \n",
       "4              6             1800     1.216667               171  1.524067   \n",
       "\n",
       "   top_quartile_HVAR  most_helpful        class  \n",
       "0           1.781095             1  neg_helpful  \n",
       "1           0.941812             1  neg_helpful  \n",
       "2           0.731463             1  neg_helpful  \n",
       "3           0.937360             1  neg_helpful  \n",
       "4           0.480200             1  neg_helpful  "
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc3_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undetermined     26000\n",
       "neg_helpful      13000\n",
       "neg_unhelpful    13000\n",
       "pos_unhelpful    13000\n",
       "pos_helpful      13000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc3_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>review_age_days</th>\n",
       "      <th>annual_HVAR</th>\n",
       "      <th>book_num_reviews</th>\n",
       "      <th>std_HVAR</th>\n",
       "      <th>top_quartile_HVAR</th>\n",
       "      <th>most_helpful</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0451239113</td>\n",
       "      <td>1</td>\n",
       "      <td>Parker's writings have dwindled to the point o...</td>\n",
       "      <td>2012-06-09</td>\n",
       "      <td>AN9V3LI0G85K5</td>\n",
       "      <td>Ron cz</td>\n",
       "      <td>Parker's Lost It!!!!!!!!!!</td>\n",
       "      <td>1339200000</td>\n",
       "      <td>6</td>\n",
       "      <td>774</td>\n",
       "      <td>2.829457</td>\n",
       "      <td>16</td>\n",
       "      <td>1.636546</td>\n",
       "      <td>1.781095</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0026045702</td>\n",
       "      <td>1</td>\n",
       "      <td>The original version of Joy is a strong conten...</td>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>A2K33VWYQC9C2W</td>\n",
       "      <td>jerry i h</td>\n",
       "      <td>Worthless Garbage</td>\n",
       "      <td>1118880000</td>\n",
       "      <td>23</td>\n",
       "      <td>3324</td>\n",
       "      <td>2.525572</td>\n",
       "      <td>102</td>\n",
       "      <td>2.269745</td>\n",
       "      <td>0.941812</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0380818612</td>\n",
       "      <td>1</td>\n",
       "      <td>I struggled to identify with her main characte...</td>\n",
       "      <td>2010-02-02</td>\n",
       "      <td>A3NY49QVQJQK7P</td>\n",
       "      <td>Kevin Watt \"I know that poetry is indispensab...</td>\n",
       "      <td>Awful.  Not up to her usual awesomeness.  Slow...</td>\n",
       "      <td>1265068800</td>\n",
       "      <td>4</td>\n",
       "      <td>1632</td>\n",
       "      <td>0.894608</td>\n",
       "      <td>57</td>\n",
       "      <td>1.681225</td>\n",
       "      <td>0.731463</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0057PFWDI</td>\n",
       "      <td>1</td>\n",
       "      <td>I found myself rolling my eyes and laughing wh...</td>\n",
       "      <td>2013-03-19</td>\n",
       "      <td>A1GS6FEGHFNIG</td>\n",
       "      <td>Deana</td>\n",
       "      <td>Hmmm</td>\n",
       "      <td>1363651200</td>\n",
       "      <td>3</td>\n",
       "      <td>491</td>\n",
       "      <td>2.230143</td>\n",
       "      <td>35</td>\n",
       "      <td>0.777522</td>\n",
       "      <td>0.937360</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0613171373</td>\n",
       "      <td>1</td>\n",
       "      <td>He was severely abused, (insert graphic detail...</td>\n",
       "      <td>2009-08-18</td>\n",
       "      <td>A3HQD8NJZLA1MO</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>This is a perfect candidate for a book burning</td>\n",
       "      <td>1250553600</td>\n",
       "      <td>6</td>\n",
       "      <td>1800</td>\n",
       "      <td>1.216667</td>\n",
       "      <td>171</td>\n",
       "      <td>1.524067</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  0451239113        1  Parker's writings have dwindled to the point o...   \n",
       "1  0026045702        1  The original version of Joy is a strong conten...   \n",
       "2  0380818612        1  I struggled to identify with her main characte...   \n",
       "3  B0057PFWDI        1  I found myself rolling my eyes and laughing wh...   \n",
       "4  0613171373        1  He was severely abused, (insert graphic detail...   \n",
       "\n",
       "   reviewTime      reviewerID  \\\n",
       "0  2012-06-09   AN9V3LI0G85K5   \n",
       "1  2005-06-16  A2K33VWYQC9C2W   \n",
       "2  2010-02-02  A3NY49QVQJQK7P   \n",
       "3  2013-03-19   A1GS6FEGHFNIG   \n",
       "4  2009-08-18  A3HQD8NJZLA1MO   \n",
       "\n",
       "                                       reviewerName  \\\n",
       "0                                            Ron cz   \n",
       "1                                         jerry i h   \n",
       "2  Kevin Watt \"I know that poetry is indispensab...   \n",
       "3                                             Deana   \n",
       "4                                   Amazon Customer   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                         Parker's Lost It!!!!!!!!!!      1339200000   \n",
       "1                                  Worthless Garbage      1118880000   \n",
       "2  Awful.  Not up to her usual awesomeness.  Slow...      1265068800   \n",
       "3                                               Hmmm      1363651200   \n",
       "4     This is a perfect candidate for a book burning      1250553600   \n",
       "\n",
       "   helpful_votes  review_age_days  annual_HVAR  book_num_reviews  std_HVAR  \\\n",
       "0              6              774     2.829457                16  1.636546   \n",
       "1             23             3324     2.525572               102  2.269745   \n",
       "2              4             1632     0.894608                57  1.681225   \n",
       "3              3              491     2.230143                35  0.777522   \n",
       "4              6             1800     1.216667               171  1.524067   \n",
       "\n",
       "   top_quartile_HVAR  most_helpful        class  \n",
       "0           1.781095             1  neg_helpful  \n",
       "1           0.941812             1  neg_helpful  \n",
       "2           0.731463             1  neg_helpful  \n",
       "3           0.937360             1  neg_helpful  \n",
       "4           0.480200             1  neg_helpful  "
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc3_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unhelpful       26000\n",
       "undetermined    26000\n",
       "helpful         26000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce to 3 classes instead of 5\n",
    "mc3_train.loc[(mc3_train['class'] == 'neg_helpful') | (mc3_train['class'] == 'pos_helpful'), 'class'] = 'helpful'\n",
    "mc3_train.loc[(mc3_train['class'] == 'neg_unhelpful') | (mc3_train['class'] == 'pos_unhelpful'), 'class'] = 'unhelpful'\n",
    "mc3_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>review_age_days</th>\n",
       "      <th>annual_HVAR</th>\n",
       "      <th>book_num_reviews</th>\n",
       "      <th>std_HVAR</th>\n",
       "      <th>top_quartile_HVAR</th>\n",
       "      <th>most_helpful</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0451239113</td>\n",
       "      <td>1</td>\n",
       "      <td>Parker's writings have dwindled to the point o...</td>\n",
       "      <td>2012-06-09</td>\n",
       "      <td>AN9V3LI0G85K5</td>\n",
       "      <td>Ron cz</td>\n",
       "      <td>Parker's Lost It!!!!!!!!!!</td>\n",
       "      <td>1339200000</td>\n",
       "      <td>6</td>\n",
       "      <td>774</td>\n",
       "      <td>2.829457</td>\n",
       "      <td>16</td>\n",
       "      <td>1.636546</td>\n",
       "      <td>1.781095</td>\n",
       "      <td>1</td>\n",
       "      <td>helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0026045702</td>\n",
       "      <td>1</td>\n",
       "      <td>The original version of Joy is a strong conten...</td>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>A2K33VWYQC9C2W</td>\n",
       "      <td>jerry i h</td>\n",
       "      <td>Worthless Garbage</td>\n",
       "      <td>1118880000</td>\n",
       "      <td>23</td>\n",
       "      <td>3324</td>\n",
       "      <td>2.525572</td>\n",
       "      <td>102</td>\n",
       "      <td>2.269745</td>\n",
       "      <td>0.941812</td>\n",
       "      <td>1</td>\n",
       "      <td>helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0380818612</td>\n",
       "      <td>1</td>\n",
       "      <td>I struggled to identify with her main characte...</td>\n",
       "      <td>2010-02-02</td>\n",
       "      <td>A3NY49QVQJQK7P</td>\n",
       "      <td>Kevin Watt \"I know that poetry is indispensab...</td>\n",
       "      <td>Awful.  Not up to her usual awesomeness.  Slow...</td>\n",
       "      <td>1265068800</td>\n",
       "      <td>4</td>\n",
       "      <td>1632</td>\n",
       "      <td>0.894608</td>\n",
       "      <td>57</td>\n",
       "      <td>1.681225</td>\n",
       "      <td>0.731463</td>\n",
       "      <td>1</td>\n",
       "      <td>helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0057PFWDI</td>\n",
       "      <td>1</td>\n",
       "      <td>I found myself rolling my eyes and laughing wh...</td>\n",
       "      <td>2013-03-19</td>\n",
       "      <td>A1GS6FEGHFNIG</td>\n",
       "      <td>Deana</td>\n",
       "      <td>Hmmm</td>\n",
       "      <td>1363651200</td>\n",
       "      <td>3</td>\n",
       "      <td>491</td>\n",
       "      <td>2.230143</td>\n",
       "      <td>35</td>\n",
       "      <td>0.777522</td>\n",
       "      <td>0.937360</td>\n",
       "      <td>1</td>\n",
       "      <td>helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0613171373</td>\n",
       "      <td>1</td>\n",
       "      <td>He was severely abused, (insert graphic detail...</td>\n",
       "      <td>2009-08-18</td>\n",
       "      <td>A3HQD8NJZLA1MO</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>This is a perfect candidate for a book burning</td>\n",
       "      <td>1250553600</td>\n",
       "      <td>6</td>\n",
       "      <td>1800</td>\n",
       "      <td>1.216667</td>\n",
       "      <td>171</td>\n",
       "      <td>1.524067</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>1</td>\n",
       "      <td>helpful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  0451239113        1  Parker's writings have dwindled to the point o...   \n",
       "1  0026045702        1  The original version of Joy is a strong conten...   \n",
       "2  0380818612        1  I struggled to identify with her main characte...   \n",
       "3  B0057PFWDI        1  I found myself rolling my eyes and laughing wh...   \n",
       "4  0613171373        1  He was severely abused, (insert graphic detail...   \n",
       "\n",
       "   reviewTime      reviewerID  \\\n",
       "0  2012-06-09   AN9V3LI0G85K5   \n",
       "1  2005-06-16  A2K33VWYQC9C2W   \n",
       "2  2010-02-02  A3NY49QVQJQK7P   \n",
       "3  2013-03-19   A1GS6FEGHFNIG   \n",
       "4  2009-08-18  A3HQD8NJZLA1MO   \n",
       "\n",
       "                                       reviewerName  \\\n",
       "0                                            Ron cz   \n",
       "1                                         jerry i h   \n",
       "2  Kevin Watt \"I know that poetry is indispensab...   \n",
       "3                                             Deana   \n",
       "4                                   Amazon Customer   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                         Parker's Lost It!!!!!!!!!!      1339200000   \n",
       "1                                  Worthless Garbage      1118880000   \n",
       "2  Awful.  Not up to her usual awesomeness.  Slow...      1265068800   \n",
       "3                                               Hmmm      1363651200   \n",
       "4     This is a perfect candidate for a book burning      1250553600   \n",
       "\n",
       "   helpful_votes  review_age_days  annual_HVAR  book_num_reviews  std_HVAR  \\\n",
       "0              6              774     2.829457                16  1.636546   \n",
       "1             23             3324     2.525572               102  2.269745   \n",
       "2              4             1632     0.894608                57  1.681225   \n",
       "3              3              491     2.230143                35  0.777522   \n",
       "4              6             1800     1.216667               171  1.524067   \n",
       "\n",
       "   top_quartile_HVAR  most_helpful    class  \n",
       "0           1.781095             1  helpful  \n",
       "1           0.941812             1  helpful  \n",
       "2           0.731463             1  helpful  \n",
       "3           0.937360             1  helpful  \n",
       "4           0.480200             1  helpful  "
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc3_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our 5-class training dataset is now 7500 reviews.\n"
     ]
    }
   ],
   "source": [
    "# Assemble 5-class dev set\n",
    "\n",
    "mc5_dev = mc_dev_neg_helpful.append(mc_dev_neg_unhelpful, ignore_index=True)\n",
    "mc5_dev = mc5_dev.append(mc_dev_pos_unhelpful, ignore_index=True)\n",
    "mc5_dev = mc5_dev.append(mc_dev_pos_helpful, ignore_index=True)\n",
    "mc5_dev = mc5_dev.append(mc5_dev_undetermined, ignore_index=True)\n",
    "print(f\"Our 5-class training dataset is now {mc5_dev.shape[0]} reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our 3-class training dataset is now 9000 reviews.\n"
     ]
    }
   ],
   "source": [
    "# Assemble 3-class dev set\n",
    "\n",
    "mc3_dev = mc_dev_neg_helpful.append(mc_dev_neg_unhelpful, ignore_index=True)\n",
    "mc3_dev = mc3_dev.append(mc_dev_pos_unhelpful, ignore_index=True)\n",
    "mc3_dev = mc3_dev.append(mc_dev_pos_helpful, ignore_index=True)\n",
    "mc3_dev = mc3_dev.append(mc3_dev_undetermined, ignore_index=True)\n",
    "print(f\"Our 3-class training dataset is now {mc3_dev.shape[0]} reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "helpful         3000\n",
       "undetermined    3000\n",
       "unhelpful       3000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce to 3 classes instead of 5\n",
    "mc3_dev.loc[(mc3_dev['class'] == 'neg_helpful') | (mc3_dev['class'] == 'pos_helpful'), 'class'] = 'helpful'\n",
    "mc3_dev.loc[(mc3_dev['class'] == 'neg_unhelpful') | (mc3_dev['class'] == 'pos_unhelpful'), 'class'] = 'unhelpful'\n",
    "mc3_dev['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>review_age_days</th>\n",
       "      <th>annual_HVAR</th>\n",
       "      <th>book_num_reviews</th>\n",
       "      <th>std_HVAR</th>\n",
       "      <th>top_quartile_HVAR</th>\n",
       "      <th>most_helpful</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0805096663</td>\n",
       "      <td>1</td>\n",
       "      <td>O'Reilly is carried away with his own view on ...</td>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>AFY1YIAQD5Y0J</td>\n",
       "      <td>aPerson</td>\n",
       "      <td>Fictional History</td>\n",
       "      <td>1349395200</td>\n",
       "      <td>26</td>\n",
       "      <td>656</td>\n",
       "      <td>14.466463</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>44.447703</td>\n",
       "      <td>1.133540</td>\n",
       "      <td>1</td>\n",
       "      <td>helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0983392900</td>\n",
       "      <td>1</td>\n",
       "      <td>Just because the reading audience is younger, ...</td>\n",
       "      <td>2011-12-27</td>\n",
       "      <td>A309Z6WBC24ZVA</td>\n",
       "      <td>Dona W. Gould</td>\n",
       "      <td>YA usually expects polished, professional writing</td>\n",
       "      <td>1324944000</td>\n",
       "      <td>7</td>\n",
       "      <td>939</td>\n",
       "      <td>2.720980</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.809796</td>\n",
       "      <td>1.881270</td>\n",
       "      <td>1</td>\n",
       "      <td>helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>078693560X</td>\n",
       "      <td>1</td>\n",
       "      <td>I purchased this book at the same time that I ...</td>\n",
       "      <td>2003-01-18</td>\n",
       "      <td>A223LGYL4WGN5K</td>\n",
       "      <td>Carrie Johnson</td>\n",
       "      <td>Think like a quarterback and Pass!</td>\n",
       "      <td>1042848000</td>\n",
       "      <td>6</td>\n",
       "      <td>4204</td>\n",
       "      <td>0.520932</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.279628</td>\n",
       "      <td>0.438973</td>\n",
       "      <td>1</td>\n",
       "      <td>helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1595910743</td>\n",
       "      <td>1</td>\n",
       "      <td>A couple of W.'s bidness buds, \"Bush Pioneers,...</td>\n",
       "      <td>2013-03-30</td>\n",
       "      <td>A2YP7JPI48MRG8</td>\n",
       "      <td>S. J. Snyder \"De gustibus non disputandum\"</td>\n",
       "      <td>Good effing doorknob</td>\n",
       "      <td>1364601600</td>\n",
       "      <td>5</td>\n",
       "      <td>480</td>\n",
       "      <td>3.802083</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.174561</td>\n",
       "      <td>3.328267</td>\n",
       "      <td>1</td>\n",
       "      <td>helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0891093117</td>\n",
       "      <td>1</td>\n",
       "      <td>Parenting with love and Logic was extremely di...</td>\n",
       "      <td>2004-02-24</td>\n",
       "      <td>A3TCHJ7YERQ938</td>\n",
       "      <td>Amy A Adams</td>\n",
       "      <td>Not for my family</td>\n",
       "      <td>1077580800</td>\n",
       "      <td>90</td>\n",
       "      <td>3802</td>\n",
       "      <td>8.640189</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.467418</td>\n",
       "      <td>1.236244</td>\n",
       "      <td>1</td>\n",
       "      <td>helpful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  0805096663        1  O'Reilly is carried away with his own view on ...   \n",
       "1  0983392900        1  Just because the reading audience is younger, ...   \n",
       "2  078693560X        1  I purchased this book at the same time that I ...   \n",
       "3  1595910743        1  A couple of W.'s bidness buds, \"Bush Pioneers,...   \n",
       "4  0891093117        1  Parenting with love and Logic was extremely di...   \n",
       "\n",
       "   reviewTime      reviewerID                                reviewerName  \\\n",
       "0  2012-10-05   AFY1YIAQD5Y0J                                     aPerson   \n",
       "1  2011-12-27  A309Z6WBC24ZVA                               Dona W. Gould   \n",
       "2  2003-01-18  A223LGYL4WGN5K                              Carrie Johnson   \n",
       "3  2013-03-30  A2YP7JPI48MRG8  S. J. Snyder \"De gustibus non disputandum\"   \n",
       "4  2004-02-24  A3TCHJ7YERQ938                                 Amy A Adams   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                  Fictional History      1349395200   \n",
       "1  YA usually expects polished, professional writing      1324944000   \n",
       "2                 Think like a quarterback and Pass!      1042848000   \n",
       "3                               Good effing doorknob      1364601600   \n",
       "4                                  Not for my family      1077580800   \n",
       "\n",
       "   helpful_votes  review_age_days  annual_HVAR  book_num_reviews   std_HVAR  \\\n",
       "0             26              656    14.466463            1222.0  44.447703   \n",
       "1              7              939     2.720980              30.0   9.809796   \n",
       "2              6             4204     0.520932              10.0   0.279628   \n",
       "3              5              480     3.802083               5.0   3.174561   \n",
       "4             90             3802     8.640189              12.0   8.467418   \n",
       "\n",
       "   top_quartile_HVAR  most_helpful    class  \n",
       "0           1.133540             1  helpful  \n",
       "1           1.881270             1  helpful  \n",
       "2           0.438973             1  helpful  \n",
       "3           3.328267             1  helpful  \n",
       "4           1.236244             1  helpful  "
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc3_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['helpful' 'undetermined' 'unhelpful']\n",
      "['neg_helpful' 'neg_unhelpful' 'pos_helpful' 'pos_unhelpful'\n",
      " 'undetermined']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le3 = preprocessing.LabelEncoder()\n",
    "mc3_train['label'] = le3.fit_transform(mc3_train['class'])\n",
    "mc3_dev['label'] = le3.fit_transform(mc3_dev['class'])\n",
    "\n",
    "print(le3.inverse_transform([0,1,2]))\n",
    "\n",
    "le5 = preprocessing.LabelEncoder()\n",
    "mc5_train['label'] = le5.fit_transform(mc5_train['class'])\n",
    "mc5_dev['label'] = le5.fit_transform(mc5_dev['class'])\n",
    "\n",
    "print(le5.inverse_transform([0,1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>review_age_days</th>\n",
       "      <th>annual_HVAR</th>\n",
       "      <th>book_num_reviews</th>\n",
       "      <th>std_HVAR</th>\n",
       "      <th>top_quartile_HVAR</th>\n",
       "      <th>most_helpful</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0451239113</td>\n",
       "      <td>1</td>\n",
       "      <td>Parker's writings have dwindled to the point o...</td>\n",
       "      <td>2012-06-09</td>\n",
       "      <td>AN9V3LI0G85K5</td>\n",
       "      <td>Ron cz</td>\n",
       "      <td>Parker's Lost It!!!!!!!!!!</td>\n",
       "      <td>1339200000</td>\n",
       "      <td>6</td>\n",
       "      <td>774</td>\n",
       "      <td>2.829457</td>\n",
       "      <td>16</td>\n",
       "      <td>1.636546</td>\n",
       "      <td>1.781095</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0026045702</td>\n",
       "      <td>1</td>\n",
       "      <td>The original version of Joy is a strong conten...</td>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>A2K33VWYQC9C2W</td>\n",
       "      <td>jerry i h</td>\n",
       "      <td>Worthless Garbage</td>\n",
       "      <td>1118880000</td>\n",
       "      <td>23</td>\n",
       "      <td>3324</td>\n",
       "      <td>2.525572</td>\n",
       "      <td>102</td>\n",
       "      <td>2.269745</td>\n",
       "      <td>0.941812</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0380818612</td>\n",
       "      <td>1</td>\n",
       "      <td>I struggled to identify with her main characte...</td>\n",
       "      <td>2010-02-02</td>\n",
       "      <td>A3NY49QVQJQK7P</td>\n",
       "      <td>Kevin Watt \"I know that poetry is indispensab...</td>\n",
       "      <td>Awful.  Not up to her usual awesomeness.  Slow...</td>\n",
       "      <td>1265068800</td>\n",
       "      <td>4</td>\n",
       "      <td>1632</td>\n",
       "      <td>0.894608</td>\n",
       "      <td>57</td>\n",
       "      <td>1.681225</td>\n",
       "      <td>0.731463</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0057PFWDI</td>\n",
       "      <td>1</td>\n",
       "      <td>I found myself rolling my eyes and laughing wh...</td>\n",
       "      <td>2013-03-19</td>\n",
       "      <td>A1GS6FEGHFNIG</td>\n",
       "      <td>Deana</td>\n",
       "      <td>Hmmm</td>\n",
       "      <td>1363651200</td>\n",
       "      <td>3</td>\n",
       "      <td>491</td>\n",
       "      <td>2.230143</td>\n",
       "      <td>35</td>\n",
       "      <td>0.777522</td>\n",
       "      <td>0.937360</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0613171373</td>\n",
       "      <td>1</td>\n",
       "      <td>He was severely abused, (insert graphic detail...</td>\n",
       "      <td>2009-08-18</td>\n",
       "      <td>A3HQD8NJZLA1MO</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>This is a perfect candidate for a book burning</td>\n",
       "      <td>1250553600</td>\n",
       "      <td>6</td>\n",
       "      <td>1800</td>\n",
       "      <td>1.216667</td>\n",
       "      <td>171</td>\n",
       "      <td>1.524067</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>1</td>\n",
       "      <td>neg_helpful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  0451239113        1  Parker's writings have dwindled to the point o...   \n",
       "1  0026045702        1  The original version of Joy is a strong conten...   \n",
       "2  0380818612        1  I struggled to identify with her main characte...   \n",
       "3  B0057PFWDI        1  I found myself rolling my eyes and laughing wh...   \n",
       "4  0613171373        1  He was severely abused, (insert graphic detail...   \n",
       "\n",
       "   reviewTime      reviewerID  \\\n",
       "0  2012-06-09   AN9V3LI0G85K5   \n",
       "1  2005-06-16  A2K33VWYQC9C2W   \n",
       "2  2010-02-02  A3NY49QVQJQK7P   \n",
       "3  2013-03-19   A1GS6FEGHFNIG   \n",
       "4  2009-08-18  A3HQD8NJZLA1MO   \n",
       "\n",
       "                                       reviewerName  \\\n",
       "0                                            Ron cz   \n",
       "1                                         jerry i h   \n",
       "2  Kevin Watt \"I know that poetry is indispensab...   \n",
       "3                                             Deana   \n",
       "4                                   Amazon Customer   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                         Parker's Lost It!!!!!!!!!!      1339200000   \n",
       "1                                  Worthless Garbage      1118880000   \n",
       "2  Awful.  Not up to her usual awesomeness.  Slow...      1265068800   \n",
       "3                                               Hmmm      1363651200   \n",
       "4     This is a perfect candidate for a book burning      1250553600   \n",
       "\n",
       "   helpful_votes  review_age_days  annual_HVAR  book_num_reviews  std_HVAR  \\\n",
       "0              6              774     2.829457                16  1.636546   \n",
       "1             23             3324     2.525572               102  2.269745   \n",
       "2              4             1632     0.894608                57  1.681225   \n",
       "3              3              491     2.230143                35  0.777522   \n",
       "4              6             1800     1.216667               171  1.524067   \n",
       "\n",
       "   top_quartile_HVAR  most_helpful        class  label  \n",
       "0           1.781095             1  neg_helpful      0  \n",
       "1           0.941812             1  neg_helpful      0  \n",
       "2           0.731463             1  neg_helpful      0  \n",
       "3           0.937360             1  neg_helpful      0  \n",
       "4           0.480200             1  neg_helpful      0  "
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc5_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewText', 'overall', 'most_helpful'], dtype='object')"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc5_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc5_train = shuffle(mc5_train,random_state=42)[['reviewText','label']]\n",
    "mc5_dev = shuffle(mc5_dev,random_state=42)[['reviewText','label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    13000\n",
       "3    13000\n",
       "2    13000\n",
       "1    13000\n",
       "0    13000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc5_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28450</th>\n",
       "      <td>If texting has become the modern way of commun...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50670</th>\n",
       "      <td>Mr. Taubes has done a great service by pulling...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15811</th>\n",
       "      <td>Um yeah, I still wonder why I bought this book...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14668</th>\n",
       "      <td>This book is not worth the 5 to 10 minutes it ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57899</th>\n",
       "      <td>This book is fascinating. I was recommended it...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  label\n",
       "28450  If texting has become the modern way of commun...      3\n",
       "50670  Mr. Taubes has done a great service by pulling...      2\n",
       "15811  Um yeah, I still wonder why I bought this book...      1\n",
       "14668  This book is not worth the 5 to 10 minutes it ...      1\n",
       "57899  This book is fascinating. I was recommended it...      4"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc5_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mc5 = mc5_train['reviewText']\n",
    "X_dev_mc5 = mc5_dev['reviewText']\n",
    "\n",
    "\n",
    "y_train_mc5 = mc5_train['label']\n",
    "y_dev_mc5 = mc5_dev['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count: 2234573\n"
     ]
    }
   ],
   "source": [
    "# Transform text examples\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                             #tokenizer=Tokenizer,\n",
    "                             analyzer='word',\n",
    "                             stop_words=None,\n",
    "                             token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'|\\*|\\-|\\;|\\:|\\,|\\.\",\n",
    "                             ngram_range=(1,2),\n",
    "                             max_features=None)\n",
    "\n",
    "X_train_mc5_vec = vectorizer.fit_transform(X_train_mc5)\n",
    "X_dev_mc5_vec = vectorizer.transform(X_dev_mc5)\n",
    "\n",
    "print(\"Token Count: {}\".format(len(vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 23 epochs took 26 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   26.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=-1, penalty='l2', random_state=42, solver='saga',\n",
       "          tol=0.0001, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more than 2 classes...multinomial\n",
    "\n",
    "# binary problem\n",
    "\n",
    "# The SAGA solver is a variant of SAG that also supports the non-smooth penalty=l1 option (i.e. L1 Regularization).\n",
    "# This is therefore the solver of choice for sparse multinomial logistic regression and it’s also suitable very Large datasets.\n",
    "\n",
    "# C = inverse of regularization strength; pos float; smaller = stronger regularization\n",
    "\n",
    "clf = LogisticRegression(penalty='l2',\n",
    "                         C=1.0,\n",
    "                         random_state=42,\n",
    "                         solver='saga',\n",
    "                         multi_class='multinomial',\n",
    "                         max_iter=100,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_train_mc5_vec, y_train_mc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_predicted_labels = clf.predict(X_dev_svd)\n",
    "dev_mc5_predicted_labels = clf.predict(X_dev_mc5_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifer - 5 class\n",
      "-------------\n",
      "\n",
      "Accuracy on test set: 0.562\n",
      "f_1 score (Weighted): 0.554\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with various f1 metrics\n",
    "f1_weighted = metrics.f1_score(y_dev_mc5, dev_mc5_predicted_labels, average='weighted')\n",
    "accuracy = metrics.accuracy_score(y_dev_mc5, dev_mc5_predicted_labels)\n",
    "    \n",
    "print('Logistic Regression Classifer - 5 class')\n",
    "print('-------------\\n')\n",
    "print('Accuracy on test set: {:0.3f}'.format(accuracy))\n",
    "print('f_1 score (Weighted): {:0.3f}'.format(f1_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  neg_helpful       0.61      0.67      0.63      1500\n",
      "neg_unhelpful       0.63      0.62      0.63      1500\n",
      "  pos_helpful       0.53      0.63      0.57      1500\n",
      "pos_unhelpful       0.56      0.59      0.57      1500\n",
      " undetermined       0.45      0.30      0.36      1500\n",
      "\n",
      "    micro avg       0.56      0.56      0.56      7500\n",
      "    macro avg       0.56      0.56      0.55      7500\n",
      " weighted avg       0.56      0.56      0.55      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = le5.inverse_transform([0,1,2,3,4])\n",
    "\n",
    "print(classification_report(y_dev_mc5, dev_mc5_predicted_labels, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc3_train = shuffle(mc3_train,random_state=42)[['reviewText','label']]\n",
    "mc3_dev = shuffle(mc3_dev,random_state=42)[['reviewText','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    26000\n",
       "1    26000\n",
       "0    26000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc3_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mc3 = mc3_train['reviewText']\n",
    "X_dev_mc3 = mc3_dev['reviewText']\n",
    "\n",
    "\n",
    "y_train_mc3 = mc3_train['label']\n",
    "y_dev_mc3 = mc3_dev['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count: 2549824\n"
     ]
    }
   ],
   "source": [
    "# Transform text examples\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                             #tokenizer=Tokenizer,\n",
    "                             analyzer='word',\n",
    "                             stop_words=None,\n",
    "                             token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'|\\*|\\-|\\;|\\:|\\,|\\.\",\n",
    "                             ngram_range=(1,2),\n",
    "                             max_features=None)\n",
    "\n",
    "X_train_mc3_vec = vectorizer.fit_transform(X_train_mc3)\n",
    "X_dev_mc3_vec = vectorizer.transform(X_dev_mc3)\n",
    "\n",
    "print(\"Token Count: {}\".format(len(vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brad\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Brad\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Brad\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1297: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
       "          penalty='l2', random_state=42, solver='warn', tol=0.0001,\n",
       "          verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more than 2 classes...multinomial\n",
    "\n",
    "# binary problem\n",
    "\n",
    "# The SAGA solver is a variant of SAG that also supports the non-smooth penalty=l1 option (i.e. L1 Regularization).\n",
    "# This is therefore the solver of choice for sparse multinomial logistic regression and it’s also suitable very Large datasets.\n",
    "\n",
    "# C = inverse of regularization strength; pos float; smaller = stronger regularization\n",
    "\n",
    "clf = LogisticRegression(penalty='l2',\n",
    "                         C=1.0,\n",
    "                         random_state=42,\n",
    "                         #solver='saga',\n",
    "                         #multi_class='multinomial',\n",
    "                         max_iter=100,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_train_mc3_vec, y_train_mc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_predicted_labels = clf.predict(X_dev_svd)\n",
    "dev_mc3_predicted_labels = clf.predict(X_dev_mc3_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifer - 3 class\n",
      "-------------\n",
      "\n",
      "Accuracy on test set: 0.551\n",
      "f_1 score (Weighted): 0.551\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with various f1 metrics\n",
    "f1_weighted = metrics.f1_score(y_dev_mc3, dev_mc3_predicted_labels, average='weighted')\n",
    "accuracy = metrics.accuracy_score(y_dev_mc3, dev_mc3_predicted_labels)\n",
    "    \n",
    "print('Logistic Regression Classifer - 3 class')\n",
    "print('-------------\\n')\n",
    "print('Accuracy on test set: {:0.3f}'.format(accuracy))\n",
    "print('f_1 score (Weighted): {:0.3f}'.format(f1_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1653,  717,  630],\n",
       "       [ 873, 1496,  631],\n",
       "       [ 567,  620, 1813]], dtype=int64)"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_dev_mc3, dev_mc3_predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     helpful       0.53      0.55      0.54      3000\n",
      "undetermined       0.53      0.50      0.51      3000\n",
      "   unhelpful       0.59      0.60      0.60      3000\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      9000\n",
      "   macro avg       0.55      0.55      0.55      9000\n",
      "weighted avg       0.55      0.55      0.55      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = le3.inverse_transform([0,1,2])\n",
    "\n",
    "print(classification_report(y_dev_mc3, dev_mc3_predicted_labels, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-class baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['helpful', 'undetermined', 'unhelpful'], dtype=object)"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le3.inverse_transform([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62226</th>\n",
       "      <td>In a nutshell, if you don't have this book, yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42449</th>\n",
       "      <td>This is one of the popular &amp;quot;female myster...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26120</th>\n",
       "      <td>Came in perfect shape in the regular mail.  Ga...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37483</th>\n",
       "      <td>It's a plot that has been done numerous times,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20944</th>\n",
       "      <td>BAD BOOK. Characters  were not  even  close to...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  label\n",
       "62226  In a nutshell, if you don't have this book, yo...      1\n",
       "42449  This is one of the popular &quot;female myster...      0\n",
       "26120  Came in perfect shape in the regular mail.  Ga...      2\n",
       "37483  It's a plot that has been done numerous times,...      2\n",
       "20944  BAD BOOK. Characters  were not  even  close to...      2"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc3_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42449</th>\n",
       "      <td>This is one of the popular &amp;quot;female myster...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26120</th>\n",
       "      <td>Came in perfect shape in the regular mail.  Ga...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37483</th>\n",
       "      <td>It's a plot that has been done numerous times,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20944</th>\n",
       "      <td>BAD BOOK. Characters  were not  even  close to...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27336</th>\n",
       "      <td>I didn't really know what to expect when I bor...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683</th>\n",
       "      <td>I bought the book despite the bad reviews I re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30708</th>\n",
       "      <td>A Million Suns picks up three months after the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6322</th>\n",
       "      <td>Robert Burney compares himself to John Bradsha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10055</th>\n",
       "      <td>Some people have said it far more eloquently t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>Bad. Bad. Bad. It CAN get worse. Why did I rea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31720</th>\n",
       "      <td>they break up and get back together.it reminds...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31124</th>\n",
       "      <td>Like the other ones, enjoyed it immensely.  Al...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45407</th>\n",
       "      <td>Many readers of Paul Reid's The Last Lion: Def...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29624</th>\n",
       "      <td>I had read Secret Sanction and really enjoyed ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49181</th>\n",
       "      <td>As the author herself tells in a note, it was ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40112</th>\n",
       "      <td>For Men Only by Shaunti and Jeff Feldhahn is n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>***Spoiler Alert***Well, I loved the book in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13159</th>\n",
       "      <td>Please read the 1 star reviews before you read...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12586</th>\n",
       "      <td>when i read the description  of this book i wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20589</th>\n",
       "      <td>I suspect from the other reviews the story is ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8786</th>\n",
       "      <td>NOTE: Updated to include a more recent reading...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30839</th>\n",
       "      <td>I personally think this is one of the best che...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>First let me say that a friend of mine told me...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21544</th>\n",
       "      <td>Prior to the last 2 books Ms. Picoult has writ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17236</th>\n",
       "      <td>Borrow this from a library, DO NOT BUY!  I did...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24958</th>\n",
       "      <td>Let's see first off this book was so bad I cou...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269</th>\n",
       "      <td>The Butterfly Effect encompasses a brief outli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27761</th>\n",
       "      <td>Throughout my reading of this fantastic piece,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25326</th>\n",
       "      <td>this writer should find a different venue and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19302</th>\n",
       "      <td>I don't mind paying $2.99 for a good, quick re...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45758</th>\n",
       "      <td>In the beginning, our narrator, Jack Forman, o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9692</th>\n",
       "      <td>This is NOT the novel, but that fact is not ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40757</th>\n",
       "      <td>Before Anton LaVey, \"Satanist\" was not a label...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19457</th>\n",
       "      <td>The general story, though a little farfetched,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35920</th>\n",
       "      <td>I do not give five stars very often, this auth...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17159</th>\n",
       "      <td>I found this book to be totally confusing and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48555</th>\n",
       "      <td>Once again Amanda McCabe shows her deft way wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23483</th>\n",
       "      <td>This book is proof of the old adage that one s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23897</th>\n",
       "      <td>Okay --- spin around until you throw up. That'...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43001</th>\n",
       "      <td>Heard and enjoyed the taped version of MARS AN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8792</th>\n",
       "      <td>I own a number of Ms. King's books.  I so enjo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10627</th>\n",
       "      <td>This book was all pretty pictures and pretty b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41606</th>\n",
       "      <td>this book is written the way i would have pict...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3890</th>\n",
       "      <td>I will be very brief. This book is a nauseatin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11394</th>\n",
       "      <td>Karl Denninger's \"Leverage\" attempts to take t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31551</th>\n",
       "      <td>I'm glad I read these books backwards and star...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35773</th>\n",
       "      <td>This really works! I remember hearing about it...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>Very disappointing, with some meals totally in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18431</th>\n",
       "      <td>I like a book that &amp;#34;sells&amp;#34; me on the s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25658</th>\n",
       "      <td>I thought I was getting the text book, for a r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28693</th>\n",
       "      <td>Warning before you read, no cannibals or massa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>Owning a business. What?!? Sure, a business ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>This was a book club read and I was told it wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41090</th>\n",
       "      <td>I got this for my wife as a Christmas gift and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16023</th>\n",
       "      <td>I paid about $4.00 for this book but when it a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44131</th>\n",
       "      <td>This book is brilliant study of the Fall of So...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37194</th>\n",
       "      <td>Brave New World was one of the best fiction bo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>I just finished this book, and while I did sta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>This book reads like you're listening to your ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>Don't waste your money. This book has no redea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  label\n",
       "42449  This is one of the popular &quot;female myster...      0\n",
       "26120  Came in perfect shape in the regular mail.  Ga...      2\n",
       "37483  It's a plot that has been done numerous times,...      2\n",
       "20944  BAD BOOK. Characters  were not  even  close to...      2\n",
       "27336  I didn't really know what to expect when I bor...      2\n",
       "6683   I bought the book despite the bad reviews I re...      0\n",
       "30708  A Million Suns picks up three months after the...      2\n",
       "6322   Robert Burney compares himself to John Bradsha...      0\n",
       "10055  Some people have said it far more eloquently t...      0\n",
       "4272   Bad. Bad. Bad. It CAN get worse. Why did I rea...      0\n",
       "31720  they break up and get back together.it reminds...      2\n",
       "31124  Like the other ones, enjoyed it immensely.  Al...      2\n",
       "45407  Many readers of Paul Reid's The Last Lion: Def...      0\n",
       "29624  I had read Secret Sanction and really enjoyed ...      2\n",
       "49181  As the author herself tells in a note, it was ...      0\n",
       "40112  For Men Only by Shaunti and Jeff Feldhahn is n...      0\n",
       "1253   ***Spoiler Alert***Well, I loved the book in t...      0\n",
       "13159  Please read the 1 star reviews before you read...      2\n",
       "12586  when i read the description  of this book i wa...      0\n",
       "20589  I suspect from the other reviews the story is ...      2\n",
       "8786   NOTE: Updated to include a more recent reading...      0\n",
       "30839  I personally think this is one of the best che...      2\n",
       "35038  First let me say that a friend of mine told me...      2\n",
       "21544  Prior to the last 2 books Ms. Picoult has writ...      2\n",
       "17236  Borrow this from a library, DO NOT BUY!  I did...      2\n",
       "24958  Let's see first off this book was so bad I cou...      2\n",
       "3269   The Butterfly Effect encompasses a brief outli...      0\n",
       "27761  Throughout my reading of this fantastic piece,...      2\n",
       "25326  this writer should find a different venue and ...      2\n",
       "19302  I don't mind paying $2.99 for a good, quick re...      2\n",
       "...                                                  ...    ...\n",
       "45758  In the beginning, our narrator, Jack Forman, o...      0\n",
       "9692   This is NOT the novel, but that fact is not ex...      0\n",
       "40757  Before Anton LaVey, \"Satanist\" was not a label...      0\n",
       "19457  The general story, though a little farfetched,...      2\n",
       "35920  I do not give five stars very often, this auth...      2\n",
       "17159  I found this book to be totally confusing and ...      2\n",
       "48555  Once again Amanda McCabe shows her deft way wi...      0\n",
       "23483  This book is proof of the old adage that one s...      2\n",
       "23897  Okay --- spin around until you throw up. That'...      2\n",
       "43001  Heard and enjoyed the taped version of MARS AN...      0\n",
       "8792   I own a number of Ms. King's books.  I so enjo...      0\n",
       "10627  This book was all pretty pictures and pretty b...      0\n",
       "41606  this book is written the way i would have pict...      0\n",
       "3890   I will be very brief. This book is a nauseatin...      0\n",
       "11394  Karl Denninger's \"Leverage\" attempts to take t...      0\n",
       "31551  I'm glad I read these books backwards and star...      2\n",
       "35773  This really works! I remember hearing about it...      2\n",
       "2747   Very disappointing, with some meals totally in...      0\n",
       "18431  I like a book that &#34;sells&#34; me on the s...      2\n",
       "25658  I thought I was getting the text book, for a r...      2\n",
       "28693  Warning before you read, no cannibals or massa...      2\n",
       "5311   Owning a business. What?!? Sure, a business ma...      0\n",
       "769    This was a book club read and I was told it wa...      0\n",
       "41090  I got this for my wife as a Christmas gift and...      0\n",
       "16023  I paid about $4.00 for this book but when it a...      2\n",
       "44131  This book is brilliant study of the Fall of So...      0\n",
       "37194  Brave New World was one of the best fiction bo...      2\n",
       "6265   I just finished this book, and while I did sta...      0\n",
       "860    This book reads like you're listening to your ...      0\n",
       "15795  Don't waste your money. This book has no redea...      2\n",
       "\n",
       "[52000 rows x 2 columns]"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc3_train[(mc3_train['label'] == 0) | (mc3_train['label'] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Came in perfect shape in the regular mail.  Gave it to my very special neighbor. She was totally happy when she saw it.'"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc3_train['reviewText'][26120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc3_train['label'][20944]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mc2 = mc3_train[(mc3_train['label'] == 0) | (mc3_train['label'] == 2)]['reviewText']\n",
    "y_train_mc2 = mc3_train[(mc3_train['label'] == 0) | (mc3_train['label'] == 2)]['label']\n",
    "\n",
    "X_dev_mc2 = mc3_dev[(mc3_dev['label'] == 0) | (mc3_dev['label'] == 2)]['reviewText']\n",
    "y_dev_mc2 = mc3_dev[(mc3_dev['label'] == 0) | (mc3_dev['label'] == 2)]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52000,)"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mc2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    26000\n",
       "0    26000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_mc2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    26000\n",
       "0    26000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_mc2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count: 1865163\n"
     ]
    }
   ],
   "source": [
    "# Transform text examples\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                             #tokenizer=Tokenizer,\n",
    "                             analyzer='word',\n",
    "                             stop_words=None,\n",
    "                             token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'|\\*|\\-|\\;|\\:|\\,|\\.\",\n",
    "                             ngram_range=(1,2),\n",
    "                             max_features=None)\n",
    "\n",
    "X_train_mc2_vec = vectorizer.fit_transform(X_train_mc2)\n",
    "X_dev_mc2_vec = vectorizer.transform(X_dev_mc2)\n",
    "\n",
    "print(\"Token Count: {}\".format(len(vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 22 epochs took 9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=42, solver='saga', tol=0.0001,\n",
       "          verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more than 2 classes...multinomial\n",
    "\n",
    "# binary problem\n",
    "\n",
    "# The SAGA solver is a variant of SAG that also supports the non-smooth penalty=l1 option (i.e. L1 Regularization).\n",
    "# This is therefore the solver of choice for sparse multinomial logistic regression and it’s also suitable very Large datasets.\n",
    "\n",
    "# C = inverse of regularization strength; pos float; smaller = stronger regularization\n",
    "\n",
    "clf = LogisticRegression(penalty='l2',\n",
    "                         C=1.0,\n",
    "                         random_state=42,\n",
    "                         solver='saga',\n",
    "                         multi_class='ovr',\n",
    "                         max_iter=100,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_train_mc2_vec, y_train_mc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dev_mc2_predicted_labels = clf.predict(X_dev_mc2_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifer\n",
      "-------------\n",
      "\n",
      "Accuracy on test set: 0.728\n",
      "f_1 score (Weighted): 0.727\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with various f1 metrics\n",
    "f1_weighted = metrics.f1_score(y_dev_mc2, dev_mc2_predicted_labels, average='weighted')\n",
    "accuracy = metrics.accuracy_score(y_dev_mc2, dev_mc2_predicted_labels)\n",
    "    \n",
    "print('Logistic Regression Classifer')\n",
    "print('-------------\\n')\n",
    "print('Accuracy on test set: {:0.3f}'.format(accuracy))\n",
    "print('f_1 score (Weighted): {:0.3f}'.format(f1_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-class; no undetermined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg_helpful' 'neg_unhelpful' 'pos_helpful' 'pos_unhelpful'\n",
      " 'undetermined']\n"
     ]
    }
   ],
   "source": [
    "print(le5.inverse_transform([0,1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mc4 = mc5_train[mc5_train['label'] != 4]['reviewText']\n",
    "y_train_mc4 = mc5_train[mc5_train['label'] != 4]['label']\n",
    "\n",
    "X_dev_mc4 = mc5_dev[mc5_dev['label'] != 4]['reviewText']\n",
    "y_dev_mc4 = mc5_dev[mc5_dev['label'] != 4]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52000,)"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mc4.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    13000\n",
       "2    13000\n",
       "1    13000\n",
       "0    13000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_mc4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count: 1865163\n"
     ]
    }
   ],
   "source": [
    "# Transform text examples\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                             #tokenizer=Tokenizer,\n",
    "                             analyzer='word',\n",
    "                             stop_words=None,\n",
    "                             token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'|\\*|\\-|\\;|\\:|\\,|\\.\",\n",
    "                             ngram_range=(1,2),\n",
    "                             max_features=None)\n",
    "\n",
    "X_train_mc4_vec = vectorizer.fit_transform(X_train_mc4)\n",
    "X_dev_mc4_vec = vectorizer.transform(X_dev_mc4)\n",
    "\n",
    "print(\"Token Count: {}\".format(len(vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 19 epochs took 15 seconds\n",
      "convergence after 22 epochs took 17 seconds\n",
      "convergence after 23 epochs took 17 seconds\n",
      "convergence after 23 epochs took 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   17.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=42, solver='saga', tol=0.0001,\n",
       "          verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more than 2 classes...multinomial\n",
    "\n",
    "# binary problem\n",
    "\n",
    "# The SAGA solver is a variant of SAG that also supports the non-smooth penalty=l1 option (i.e. L1 Regularization).\n",
    "# This is therefore the solver of choice for sparse multinomial logistic regression and it’s also suitable very Large datasets.\n",
    "\n",
    "# C = inverse of regularization strength; pos float; smaller = stronger regularization\n",
    "\n",
    "clf = LogisticRegression(penalty='l2',\n",
    "                         C=1.0,\n",
    "                         random_state=42,\n",
    "                         solver='saga',\n",
    "                         multi_class='ovr',\n",
    "                         max_iter=100,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_train_mc4_vec, y_train_mc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_mc4_predicted_labels = clf.predict(X_dev_mc4_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifer\n",
      "-------------\n",
      "\n",
      "Accuracy on test set: 0.668\n",
      "f_1 score (Weighted): 0.668\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with various f1 metrics\n",
    "f1_weighted = metrics.f1_score(y_dev_mc4, dev_mc4_predicted_labels, average='weighted')\n",
    "accuracy = metrics.accuracy_score(y_dev_mc4, dev_mc4_predicted_labels)\n",
    "    \n",
    "print('Logistic Regression Classifer')\n",
    "print('-------------\\n')\n",
    "print('Accuracy on test set: {:0.3f}'.format(accuracy))\n",
    "print('f_1 score (Weighted): {:0.3f}'.format(f1_weighted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
